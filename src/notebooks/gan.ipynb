{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d26870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c09b7",
   "metadata": {},
   "source": [
    "GAN Training\n",
    "====\n",
    "An illustration of the GAN training data/loop\n",
    "\n",
    "We'll take some patches of pure-noise (from the deep ocean, with low RMS - we expect these tiles to be pure noise, since the signal is slowly varying)\n",
    "and train a GAN to reproduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take some tiles from our noisy data and display them, to illustrate what's going on\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from current_denoising.plotting import maps\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "\n",
    "# This is the \"real\" file the Laura made plots of in her paper doi:10.1017/eds.2023.41\n",
    "filepath = pathlib.Path(\n",
    "    \"/home/mh19137/geog_rdsf/data/projects/SING/richard_stuff/Table2/currents/dtu18_eigen-6c4_do0280_rr0004_cs.dat\"\n",
    ")\n",
    "assert filepath.exists()\n",
    "data = ioutils.read_currents(filepath)\n",
    "\n",
    "# Extract some tiles, rejecting the ones with high latitude or RMS\n",
    "# An RMS of 0.20 is the 50th percentile in the dtu18_eigen-6c4_do0280_rr0004_cs data,\n",
    "# and we use the same latitude threshold as Laura did\n",
    "tile_size = 32  # in grid points\n",
    "rms_threshold = 0.18\n",
    "latitude_threshold = 64.0\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    data,\n",
    "    num_tiles=512,\n",
    "    max_rms=rms_threshold,\n",
    "    max_latitude=64.0,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tile_grid = np.ones_like(data) * np.nan\n",
    "\n",
    "for tile, (y, x) in zip(tiles, indices):\n",
    "    tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(10, 5))\n",
    "maps.imshow(tile_grid, axis=axis)\n",
    "axis.imshow(\n",
    "    1.4 * np.isnan(data),\n",
    "    cmap=maps.clear2black_cmap(),\n",
    "    extent=[-180, 180, -90, 90],\n",
    "    vmin=0,\n",
    "    vmax=1.4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5479479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Turn our images into a dataloader with the right transforms\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a970944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "\n",
    "batch_size = 64\n",
    "config = {\n",
    "    \"n_epochs\": 100,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": 10,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"d_g_lr_ratio\": 4,\n",
    "    \"latent_dim\": 64,\n",
    "    \"img_size\": tile_size,\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": pathlib.Path(\"outputs/gan/\"),\n",
    "    \"plot_interval\": 10,\n",
    "}\n",
    "if not config[\"output_dir\"].is_dir():\n",
    "    config[\"output_dir\"].mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We might want to train lots of slightly different models, so write big function for the training + monitoring plots\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _fid_plot(gen_loss, disc_loss, fid_scores, config, plot_dir):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    _ = training.plot_losses(\n",
    "        gen_loss,\n",
    "        disc_loss,\n",
    "        labels=(\"Generator Loss\", \"Discriminator Loss\"),\n",
    "        axis=axes[0],\n",
    "    )\n",
    "\n",
    "    axes[1].plot([20 * i for i, _ in enumerate(fid_scores)], fid_scores)\n",
    "\n",
    "    axes[1].set_title(\"fid_score\")\n",
    "    title = f\"lr={config['learning_rate']}, d_g_lr_ratio={config['d_g_lr_ratio']}\"\n",
    "    axes[0].set_title(\"Losses\")\n",
    "    fig.savefig(plot_dir / \"fid.png\")\n",
    "\n",
    "\n",
    "def _gp_plot(gps, w_dists, config, plot_dir):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "\n",
    "    gp_arr = config[\"lambda_gp\"] * np.array(gps)\n",
    "    w_dist_arr = np.array(w_dists)\n",
    "\n",
    "    x = np.arange(len(w_dists))\n",
    "\n",
    "    axes[0].plot(x, gp_arr.mean(axis=1), label=\"Gradient Penalty\")\n",
    "    axes[0].fill_between(x, gp_arr.min(axis=1), gp_arr.max(axis=1), alpha=0.2)\n",
    "\n",
    "    axes[0].plot(x, w_dist_arr.mean(axis=1), label=\"Wasserstein Distance\")\n",
    "    axes[0].fill_between(x, w_dist_arr.min(axis=1), w_dist_arr.max(axis=1), alpha=0.2)\n",
    "\n",
    "    axes[1].plot(gp_arr.mean(axis=1) / w_dist_arr.mean(axis=1), color=\"C2\")\n",
    "    axes[1].axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "    axes[1].axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "    axes[1].set_title(\"Ratio; high -> GP dominates, low -> WD dominates\")\n",
    "    axes[0].legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "\n",
    "\n",
    "def _grad_plot(g_grads, d_grads, config, plot_dir):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "    axes[0].plot(g_grads, label=\"Generator Gradients\", color=\"C0\")\n",
    "    axes[0].plot(d_grads, label=\"Discriminator Gradients\", color=\"C1\")\n",
    "    axes[1].plot(\n",
    "        config[\"d_g_lr_ratio\"] * np.array(g_grads) / d_grads,\n",
    "        color=\"C2\",\n",
    "        label=\"ratio\",\n",
    "    )\n",
    "    axes[1].axhline(0.85, color=\"k\", linestyle=\"dashed\")\n",
    "    axes[1].axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "    for axis in axes:\n",
    "        axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "\n",
    "\n",
    "def _grad_norm_plot(grad_norms, config, plot_dir):\n",
    "    fig, axis = plt.subplots()\n",
    "    grad_norms = np.array(grad_norms)\n",
    "    x = np.arange(len(grad_norms))\n",
    "    axis.plot(x, np.mean(grad_norms, axis=1), color=\"C0\")\n",
    "    axis.fill_between(\n",
    "        x,\n",
    "        np.min(grad_norms, axis=1),\n",
    "        np.max(grad_norms, axis=1),\n",
    "        alpha=0.2,\n",
    "        color=\"C0\",\n",
    "    )\n",
    "    axis.axhline(0.9, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(1.1, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.set_title(f\"Gradient Norm\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "\n",
    "\n",
    "def train_gan(config: dict, plot_dir: pathlib.Path):\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "    \"\"\"\n",
    "    generator = dcgan.Generator(config)\n",
    "    discriminator = dcgan.Discriminator(config)\n",
    "\n",
    "    # Train the GAN\n",
    "    (\n",
    "        generator,\n",
    "        discriminator,\n",
    "        gen_loss,\n",
    "        disc_loss,\n",
    "        fid_scores,\n",
    "        w_dists,\n",
    "        gps,\n",
    "        g_grads,\n",
    "        d_grads,\n",
    "        grad_norms,\n",
    "    ) = dcgan.train(generator, discriminator, config)\n",
    "\n",
    "    # Plot training losses + FID\n",
    "    _fid_plot(gen_loss, disc_loss, fid_scores, config, plot_dir)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(gps, w_dists, config, plot_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(g_grads, d_grads, config, plot_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(grad_norms, config, plot_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    z_g = Variable(\n",
    "        torch.cuda.FloatTensor(\n",
    "            np.random.normal(0, 1, (batch_size, config[\"latent_dim\"]))\n",
    "        )\n",
    "    )\n",
    "    gen_imgs = generator(z_g)\n",
    "\n",
    "    fig = img_validation.show(gen_imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "\n",
    "    # Plot histograms of the generated and real images\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(gen_imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    axes[0].set_title(f\"Generated images - {title}\")\n",
    "    img_validation.hist(\n",
    "        next(iter(config[\"dataloader\"])),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(\"Image Hists - \" + title)\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    img_validation.fft(gen_imgs, axis=axes[0])\n",
    "    fig.suptitle(title)\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    img_validation.fft(next(iter(config[\"dataloader\"])), axis=axes[1])\n",
    "    axes[1].set_title(\"Real images FFT\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95268a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"n_epochs\"] = 40\n",
    "train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326cc56",
   "metadata": {},
   "source": [
    "Tuning Learning Rate\n",
    "----\n",
    "Here, we're looking for:\n",
    " - FID drops early (first 15 epochs)\n",
    " - Gradient norm near 1\n",
    " - $\\lambda$ GP / |W| mostly between 0.1 and 0.6\n",
    " - Wasserstein distance peaks at first, then small positive plateau (without oscillations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"\n",
    "Train a lot of different GANs with different learning rates\n",
    "\"\"\"\n",
    "\n",
    "config[\"n_epochs\"] = 41\n",
    "lrs = [\n",
    "    1e-3,\n",
    "    7e-4,\n",
    "    5e-4,\n",
    "    3e-4,\n",
    "    # 2e-4,\n",
    "    # 1e-4,\n",
    "    # 5e-5,\n",
    "]\n",
    "for lr in lrs:\n",
    "    config[\"learning_rate\"] = lr\n",
    "    config[\"output_dir\"] = pathlib.Path(f\"outputs/gan_lr_study/lr_{lr:.0e}/\")\n",
    "    if not config[\"output_dir\"].is_dir():\n",
    "        config[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "    train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f214a4",
   "metadata": {},
   "source": [
    "Balance Pass\n",
    "----\n",
    "We now want to tune the ratio of the critic/generator's learning rates.\n",
    "\n",
    "Here we will look for:\n",
    " - Effective step size (grads.png) eatio near 1 (roughly - between 0.3 and 2.0)\n",
    " - FID still decreasing\n",
    " - W still peaks then decreases, without too much noise\n",
    " - $\\lambda$ GP/|W| still between 0.1 and 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de166bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\"\"\"\n",
    "Now that I have an LR to start with, train a few GANs with different d_g_lr_ratio\n",
    "\"\"\"\n",
    "config[\"learning_rate\"] = 0.01\n",
    "for ratio in [0.5, 1, 2, 4, 8, 16]:\n",
    "    config[\"d_g_lr_ratio\"] = ratio\n",
    "    config[\"output_dir\"] = pathlib.Path(f\"outputs/gan_dg_ratio_study/ratio_{ratio:.1f}/\")\n",
    "    if not config[\"output_dir\"].is_dir():\n",
    "        config[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "    train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f15228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now that we have a sensible d_g_lr_ratio, train a longer run\n",
    "\"\"\"\n",
    "config[\"learning_rate\"] = 0.005\n",
    "config[\"d_g_lr_ratio\"] = 9\n",
    "config[\"n_epochs\"] = 800\n",
    "config[\"output_dir\"] = pathlib.Path(\"outputs/gan_final/\")\n",
    "train_gan(config, config[\"output_dir\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
