{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d26870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c09b7",
   "metadata": {},
   "source": [
    "GAN Training\n",
    "====\n",
    "An illustration of the GAN training data/loop\n",
    "\n",
    "We'll take some patches of pure-noise (from the deep ocean, with low RMS - we expect these tiles to be pure noise, since the signal is slowly varying)\n",
    "and train a GAN to reproduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take some tiles from our noisy data and display them, to illustrate what's going on\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from current_denoising.plotting import maps\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "\n",
    "# This is the \"real\" file the Laura made plots of in her paper doi:10.1017/eds.2023.41\n",
    "filepath = pathlib.Path(\n",
    "    \"/home/mh19137/geog_rdsf/data/projects/SING/richard_stuff/Table2/currents/dtu18_eigen-6c4_do0280_rr0004_cs.dat\"\n",
    ")\n",
    "assert filepath.exists()\n",
    "data = ioutils.read_currents(filepath)\n",
    "\n",
    "# Extract some tiles, rejecting the ones with high latitude or RMS\n",
    "# An RMS of 0.20 is the 50th percentile in the dtu18_eigen-6c4_do0280_rr0004_cs data,\n",
    "# and we use the same latitude threshold as Laura did\n",
    "tile_size = 32  # in grid points\n",
    "rms_threshold = 0.18\n",
    "latitude_threshold = 64.0\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    data,\n",
    "    num_tiles=512,\n",
    "    max_rms=rms_threshold,\n",
    "    max_latitude=64.0,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tile_grid = np.ones_like(data) * np.nan\n",
    "\n",
    "for tile, (y, x) in zip(tiles, indices):\n",
    "    tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(10, 5))\n",
    "maps.imshow(tile_grid, axis=axis)\n",
    "axis.imshow(\n",
    "    1.4 * np.isnan(data),\n",
    "    cmap=maps.clear2black_cmap(),\n",
    "    extent=[-180, 180, -90, 90],\n",
    "    vmin=0,\n",
    "    vmax=1.4,\n",
    ")\n",
    "fig.colorbar(axis.images[0], ax=axis, label=\"m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5479479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Turn our images into a dataloader with the right transforms\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a970944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "\n",
    "batch_size = 64\n",
    "config = {\n",
    "    \"n_epochs\": np.nan,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": 10,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"d_g_lr_ratio\": 4,\n",
    "    \"latent_dim\": 64,\n",
    "    \"img_size\": tile_size,\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": pathlib.Path(\"outputs/gan_test/\"),\n",
    "    \"plot_interval\": 10,\n",
    "}\n",
    "if not config[\"output_dir\"].is_dir():\n",
    "    config[\"output_dir\"].mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We might want to train lots of slightly different models, so write big function for the training + monitoring plots\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from torch.autograd import Variable\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _fid_plot(gen_loss, disc_loss, fid_scores, config, plot_dir, title):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    _ = training.plot_losses(\n",
    "        gen_loss,\n",
    "        disc_loss,\n",
    "        labels=(\"Generator Loss\", \"Discriminator Loss\"),\n",
    "        axis=axes[0],\n",
    "    )\n",
    "\n",
    "    axes[1].plot(\n",
    "        [config[\"plot_interval\"] * i for i, _ in enumerate(fid_scores)], fid_scores\n",
    "    )\n",
    "\n",
    "    axes[1].set_title(\"fid_score\")\n",
    "    title = f\"lr={config['learning_rate']}, d_g_lr_ratio={config['d_g_lr_ratio']}\"\n",
    "    axes[0].set_title(\"Losses\")\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"fid.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _gp_plot(gps, w_dists, config, plot_dir):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "\n",
    "    gp_arr = config[\"lambda_gp\"] * np.array(gps)\n",
    "    w_dist_arr = np.array(w_dists)\n",
    "\n",
    "    x = np.arange(len(w_dists))\n",
    "\n",
    "    axes[0].plot(x, gp_arr.mean(axis=1), label=\"Gradient Penalty\")\n",
    "    axes[0].fill_between(x, gp_arr.min(axis=1), gp_arr.max(axis=1), alpha=0.2)\n",
    "\n",
    "    axes[0].plot(x, w_dist_arr.mean(axis=1), label=\"Wasserstein Distance\")\n",
    "    axes[0].fill_between(x, w_dist_arr.min(axis=1), w_dist_arr.max(axis=1), alpha=0.2)\n",
    "\n",
    "    axes[1].plot(gp_arr.mean(axis=1) / w_dist_arr.mean(axis=1), color=\"C2\")\n",
    "    axes[1].axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "    axes[1].axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "    axes[1].set_ylim(-3, 3)\n",
    "\n",
    "    axes[1].set_title(\"Ratio; high -> GP dominates, low -> WD dominates\")\n",
    "    axes[0].legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_plot(g_grads, d_grads, config, plot_dir):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "    axes[0].plot(g_grads, label=\"Generator Gradients\", color=\"C0\")\n",
    "    axes[0].plot(d_grads, label=\"Discriminator Gradients\", color=\"C1\")\n",
    "    axes[1].plot(\n",
    "        config[\"d_g_lr_ratio\"] * np.array(g_grads) / d_grads,\n",
    "        color=\"C2\",\n",
    "        label=\"ratio\",\n",
    "    )\n",
    "    axes[1].set_title(\"G * d_g_lr_ration / D gradients\")\n",
    "    axes[1].axhline(0.85, color=\"k\", linestyle=\"dashed\")\n",
    "    axes[1].axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "    axes[1].set_ylim(0, 2)\n",
    "    for axis in axes:\n",
    "        axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_norm_plot(grad_norms, config, plot_dir):\n",
    "    fig, axis = plt.subplots()\n",
    "    grad_norms = np.array(grad_norms)\n",
    "    x = np.arange(len(grad_norms))\n",
    "    axis.plot(x, np.mean(grad_norms, axis=1), color=\"C0\")\n",
    "    axis.fill_between(\n",
    "        x,\n",
    "        np.min(grad_norms, axis=1),\n",
    "        np.max(grad_norms, axis=1),\n",
    "        alpha=0.2,\n",
    "        color=\"C0\",\n",
    "    )\n",
    "    axis.axhline(0.9, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(1.1, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.set_ylim(0, 2)\n",
    "    axis.set_title(f\"Gradient Norm\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _imgs_plot(imgs, plot_dir, title):\n",
    "    fig = img_validation.show(imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.suptitle(f\"Generated images\")\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _hist_plot(imgs, config, plot_dir, title):\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    img_validation.hist(\n",
    "        next(iter(config[\"dataloader\"])),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(f\"Image Hists - {title}\")\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _fft_plot(imgs, plot_dir, title):\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    img_validation.fft(imgs, axis=axes[0])\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    img_validation.fft(next(iter(config[\"dataloader\"])), axis=axes[1])\n",
    "    axes[1].set_title(f\"Real images FFT {title}\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    config: dict, plot_dir: pathlib.Path\n",
    ") -> tuple[torch.nn.Module, torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "\n",
    "    Returns G + D and some metrics\n",
    "    \"\"\"\n",
    "    generator = dcgan.Generator(config)\n",
    "    discriminator = dcgan.Discriminator(config)\n",
    "    metrics = {}\n",
    "\n",
    "    # Train the GAN\n",
    "    (\n",
    "        generator,\n",
    "        discriminator,\n",
    "        gen_loss,\n",
    "        disc_loss,\n",
    "        fid_scores,\n",
    "        w_dists,\n",
    "        gps,\n",
    "        g_grads,\n",
    "        d_grads,\n",
    "        grad_norms,\n",
    "    ) = dcgan.train(generator, discriminator, config)\n",
    "\n",
    "    # Plot training losses + FID\n",
    "    title = f\"lr={config['learning_rate']}, d_g_lr_ratio={config['d_g_lr_ratio']}\"\n",
    "    _fid_plot(gen_loss, disc_loss, fid_scores, config, plot_dir, title)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(gps, w_dists, config, plot_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(g_grads, d_grads, config, plot_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(grad_norms, config, plot_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    z_g = Variable(\n",
    "        torch.cuda.FloatTensor(\n",
    "            np.random.normal(0, 1, (batch_size, config[\"latent_dim\"]))\n",
    "        )\n",
    "    )\n",
    "    gen_imgs = generator(z_g)\n",
    "\n",
    "    _imgs_plot(gen_imgs, plot_dir, title)\n",
    "    _hist_plot(gen_imgs, config, plot_dir, title)\n",
    "    _fft_plot(gen_imgs, plot_dir, title)\n",
    "\n",
    "    # Track metrics\n",
    "    metrics[\"best_fid\"] = np.min(fid_scores)\n",
    "    metrics[\"final_fid\"] = fid_scores[-1]\n",
    "    metrics[\"mean_wd_gp_ratio\"] = (\n",
    "        config[\"lambda_gp\"] * np.mean(gps, axis=1) / np.mean(w_dists, axis=1)\n",
    "    ).mean()\n",
    "    metrics[\"1-mean_gradient_ratio\"] = abs(\n",
    "        1 - (config[\"d_g_lr_ratio\"] * np.array(g_grads) / d_grads).mean()\n",
    "    )\n",
    "    metrics[\"avg_grad_norm\"] = np.mean(grad_norms, axis=1)[-50:].mean()\n",
    "    metrics[\"hist_wasserstein\"] = wasserstein_distance(\n",
    "        gen_imgs.detach().cpu().numpy().flatten(),\n",
    "        next(iter(config[\"dataloader\"])).cpu().numpy().flatten(),\n",
    "    )\n",
    "\n",
    "    return generator, discriminator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95268a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"n_epochs\"] = 10\n",
    "train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326cc56",
   "metadata": {},
   "source": [
    "Tuning\n",
    "----\n",
    "Here, we're looking for:\n",
    " - FID drops early (first 15 epochs)\n",
    " - Gradient norm near 1\n",
    " - $\\lambda$ GP / |W| mostly between 0.1 and 0.6\n",
    " - Wasserstein distance peaks at first, then small positive plateau (without oscillations)\n",
    "\n",
    "We will perform a random search over some of our parameters so that we can find a decent set to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a lot of different GANs with different hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "n_runs = 500\n",
    "config = {\n",
    "    \"n_epochs\": 101,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": np.nan,\n",
    "    \"learning_rate\": np.nan,\n",
    "    \"d_g_lr_ratio\": np.nan,\n",
    "    \"latent_dim\": 64,\n",
    "    \"img_size\": tile_size,\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": None,\n",
    "    \"plot_interval\": 10,\n",
    "}\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "metrics: list[dict] = []\n",
    "out_dir = pathlib.Path(\"outputs/gan_tuning/\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(n_runs):\n",
    "    config[\"learning_rate\"] = 10 ** rng.uniform(-6, -2)\n",
    "    config[\"lambda_gp\"] = np.random.uniform(1, 20)\n",
    "    config[\"d_g_lr_ratio\"] = rng.uniform(2, 32)\n",
    "    config[\"output_dir\"] = out_dir / str(i)\n",
    "\n",
    "    config[\"output_dir\"].mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    _, _, tmp = train_gan(config, config[\"output_dir\"])\n",
    "    tmp[\"lr\"] = config[\"learning_rate\"]\n",
    "    tmp[\"lambda_gp\"] = config[\"lambda_gp\"]\n",
    "    tmp[\"d_g_lr_ratio\"] = config[\"d_g_lr_ratio\"]\n",
    "    metrics.append(tmp)\n",
    "\n",
    "with open(\"metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the metrics\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "# Lots of plots will have been made with interactive mode off, so close them all\n",
    "# and then turn it back on\n",
    "plt.close(\"all\")\n",
    "plt.ion()\n",
    "\n",
    "with open(\"metrics.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 5))\n",
    "param_names = [\"lr\", \"lambda_gp\", \"d_g_lr_ratio\"]\n",
    "metric_names = [k for k in metrics[0] if k not in param_names]\n",
    "for axis, key in zip(axes.flat, metric_names):\n",
    "    axis.plot([d[key] for d in metrics], \"o\")\n",
    "    axis.set_title(key)\n",
    "    if \"wd_gp\" in key:\n",
    "        axis.axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(-3, 3)\n",
    "    if \"gradient_ratio\" in key:\n",
    "        axis.axhline(0.85, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(0, 2)\n",
    "    if \"grad_norm\" in key:\n",
    "        axis.axhline(0.9, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.1, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(0, 2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the best runs according to each metric\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "metric_table = pd.DataFrame(metrics)\n",
    "\n",
    "top_n = 5\n",
    "\n",
    "print(\"FID: best, final\")\n",
    "display(metric_table.sort_values(\"best_fid\").head(top_n)[param_names + [\"best_fid\"]])\n",
    "display(metric_table.sort_values(\"final_fid\").head(top_n)[param_names + [\"final_fid\"]])\n",
    "\n",
    "# we want to find how close this one is to 0.3\n",
    "print(\"Gradient penalty strength\")\n",
    "display(\n",
    "    metric_table.assign(wd_gp_diff=lambda df: abs(df[\"mean_wd_gp_ratio\"] - 0.3))\n",
    "    .sort_values(\"wd_gp_diff\")\n",
    "    .head(top_n)[param_names + [\"mean_wd_gp_ratio\"]]\n",
    ")\n",
    "\n",
    "print(\"Gradient ratios\")\n",
    "display(\n",
    "    metric_table.sort_values(\"1-mean_gradient_ratio\").head(top_n)[\n",
    "        param_names + [\"1-mean_gradient_ratio\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Gradient norm\")\n",
    "display(\n",
    "    metric_table.assign(grad_norm_diff=lambda df: abs(df[\"avg_grad_norm\"] - 1.0))\n",
    "    .sort_values(\"grad_norm_diff\")\n",
    "    .head(top_n)[param_names + [\"avg_grad_norm\"]]\n",
    ")\n",
    "\n",
    "print(\"Wasserstein\")\n",
    "display(\n",
    "    metric_table.sort_values(\"hist_wasserstein\").head(top_n)[\n",
    "        param_names + [\"hist_wasserstein\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8831da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the metrics against the hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(len(metric_names), len(param_names), figsize=(12, 12))\n",
    "for ax, key in zip(axes, metric_names):\n",
    "    for axis, param in zip(ax, param_names):\n",
    "        sc = axis.scatter(\n",
    "            [d[param] for d in metrics],\n",
    "            [d[key] for d in metrics],\n",
    "            alpha=0.7,\n",
    "            label=param,\n",
    "            s=1,\n",
    "        )\n",
    "\n",
    "\n",
    "for axis, title in zip(axes[0], param_names):\n",
    "    axis.set_title(title)\n",
    "\n",
    "for axis, title in zip(axes[:, 0], metric_names):\n",
    "    axis.set_ylabel(title)\n",
    "    axis.set_xscale(\"log\")\n",
    "\n",
    "for axis in axes[2]:\n",
    "    axis.set_ylim(0, 1)\n",
    "    axis.axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "for axis in axes[4]:\n",
    "    axis.axhline(0.8, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f15228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now that we have a sensible d_g_lr_ratio, train a longer run\n",
    "\"\"\"\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 128\n",
    "config = {\n",
    "    \"n_epochs\": 300,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": 13.7,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"d_g_lr_ratio\": 12.7,\n",
    "    \"latent_dim\": 64,\n",
    "    \"img_size\": tile_size,\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": pathlib.Path(\"outputs/gan_final/\"),\n",
    "    \"plot_interval\": 10,\n",
    "}\n",
    "\n",
    "generator, discriminator, _ = train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34967dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), config[\"output_dir\"] / \"generator_final.pth\")\n",
    "torch.save(discriminator.state_dict(), config[\"output_dir\"] / \"discriminator_final.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
