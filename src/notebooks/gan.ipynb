{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d26870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate some fake data with noise in it just in case\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "images = fetch_olivetti_faces()[\"images\"]\n",
    "assert images.shape[1] == images.shape[2]\n",
    "\n",
    "# Downsample them to 32x32 to match the real data\n",
    "images = images[:, ::2, ::2]\n",
    "\n",
    "# Normalize the images to [-1, 1]\n",
    "images = 2 * (images - images.min()) / (images.max() - images.min()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5245ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot an example\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot both\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot clean data\n",
    "plot_kw = {\"cmap\": \"grey\", \"aspect\": \"auto\", \"vmin\": 0, \"vmax\": 1}\n",
    "for axis, im in zip(axes, images, strict=False):\n",
    "    axis.imshow(im, **plot_kw)\n",
    "    axis.axis(\"off\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5479479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Turn our images into a dataloader with the right transforms\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class ImageLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, images):\n",
    "        assert np.isclose(images.max(), 1.0, atol=0.01)\n",
    "        assert np.isclose(images.min(), -1.0, atol=0.01)\n",
    "\n",
    "        self.images = images\n",
    "        self.mean, self.std = images.mean(), images.std()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.FloatTensor(self.images[idx]).unsqueeze(0)\n",
    "        return image\n",
    "\n",
    "\n",
    "dataset = ImageLoader(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a970944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" First, we'll quickly train a bad model\"\"\"\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "batch_size = 64\n",
    "config = {\n",
    "    \"n_epochs\": 500,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": 10,\n",
    "    \"learning_rate\": 0.00005,\n",
    "    \"latent_dim\": 2,\n",
    "    \"img_size\": images.shape[1],\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": pathlib.Path(\"output/\"),\n",
    "}\n",
    "if not config[\"output_dir\"].is_dir():\n",
    "    config[\"output_dir\"].mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the GAN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "generator = dcgan.Generator(config)\n",
    "discriminator = dcgan.Discriminator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc602313",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the GAN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "generator, discriminator, gen_loss, disc_loss, fid_scores = dcgan.train(generator, discriminator, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068bfe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from current_denoising.plotting import training\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "_ = training.plot_losses(\n",
    "    gen_loss, disc_loss, labels=(\"Generator Loss\", \"Discriminator Loss\"), axis=axes[0]\n",
    ")\n",
    "\n",
    "axes[1].plot([20 * i for i, _ in enumerate(fid_scores)], fid_scores)\n",
    "axes[1].set_title(\"fid_score\")\n",
    "fig.savefig(\"bad_fid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6dc34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Now, we'll train a better one\"\"\"\n",
    "\n",
    "config[\"latent_dim\"] = 64\n",
    "\n",
    "generator, discriminator, gen_loss, disc_loss, fid_scores = dcgan.train(\n",
    "    dcgan.Generator(config),\n",
    "    dcgan.Discriminator(config),\n",
    "    config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acb4df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "_ = training.plot_losses(\n",
    "    gen_loss, disc_loss, labels=(\"Generator Loss\", \"Discriminator Loss\"), axis=axes[0]\n",
    ")\n",
    "\n",
    "axes[1].plot([20 * i for i, _ in enumerate(fid_scores)], fid_scores)\n",
    "axes[1].set_title(\"fid_score\")\n",
    "fig.savefig(\"good_fid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Show some generated patches\n",
    "\n",
    "\"\"\"\n",
    "from matplotlib import animation\n",
    "img_paths = sorted(list(pathlib.Path(config[\"output_dir\"]).glob(\"*/*.png\")))\n",
    "\n",
    "\n",
    "# Quick and simple version\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.axis('off')\n",
    "\n",
    "def animate(frame):\n",
    "    ax.clear()\n",
    "    ax.axis('off')\n",
    "    img = plt.imread(img_paths[frame])\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f'Epoch {frame * 20}')  # Assuming every 20 epochs\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=len(img_paths), interval=100, repeat=True)\n",
    "anim.save(\"gan_simple.mp4\", writer='ffmpeg', fps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ade2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate a new image and display it\n",
    "\"\"\"\n",
    "from torch.autograd import Variable\n",
    "\n",
    "z_g = Variable(\n",
    "    torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, config[\"latent_dim\"])))\n",
    ")\n",
    "gen_imgs = generator(z_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from current_denoising.plotting import img_validation\n",
    "\n",
    "fig = img_validation.show(gen_imgs, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03ec35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = img_validation.hist(gen_imgs, bins=50, density=True)\n",
    "fig.suptitle(\"Generated images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35e32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = img_validation.hist(next(iter(config[\"dataloader\"])), bins=50, density=True)\n",
    "fig.suptitle(\"Real images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835c542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = img_validation.fft(gen_imgs)\n",
    "fig.suptitle(\"Generated images FFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbfe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = img_validation.fft(next(iter(config[\"dataloader\"])))\n",
    "fig.suptitle(\"Real images FFT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
