{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d26870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c09b7",
   "metadata": {},
   "source": [
    "GAN Training\n",
    "====\n",
    "An illustration of the GAN training data/loop\n",
    "\n",
    "We'll take some patches of pure-noise (from the deep ocean, with low RMS - we expect these tiles to be pure noise, since the signal is slowly varying)\n",
    "and train a GAN to reproduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take some tiles from our noisy data and display them, to illustrate what's going on\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from current_denoising.plotting import maps\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "\n",
    "# This is the \"real\" file the Laura made plots of in her paper doi:10.1017/eds.2023.41\n",
    "filepath = pathlib.Path(\n",
    "    \"/home/mh19137/geog_rdsf/data/projects/SING/richard_stuff/Table2/currents/dtu18_eigen-6c4_do0280_rr0004_cs.dat\"\n",
    ")\n",
    "assert filepath.exists()\n",
    "data = ioutils.read_currents(filepath)\n",
    "\n",
    "# Extract some tiles, rejecting the ones with high latitude or RMS\n",
    "# An RMS of 0.20 is the 50th percentile in the dtu18_eigen-6c4_do0280_rr0004_cs data,\n",
    "# and we use the same latitude threshold as Laura did\n",
    "tile_size = 32  # in grid points\n",
    "rms_threshold = 0.18\n",
    "latitude_threshold = 64.0\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    data,\n",
    "    num_tiles=512,\n",
    "    max_rms=rms_threshold,\n",
    "    max_latitude=64.0,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tile_grid = np.ones_like(data) * np.nan\n",
    "\n",
    "for tile, (y, x) in zip(tiles, indices):\n",
    "    tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(10, 5))\n",
    "maps.imshow(tile_grid, axis=axis)\n",
    "axis.imshow(\n",
    "    1.4 * np.isnan(data),\n",
    "    cmap=maps.clear2black_cmap(),\n",
    "    extent=[-180, 180, -90, 90],\n",
    "    vmin=0,\n",
    "    vmax=1.4,\n",
    ")\n",
    "fig.colorbar(axis.images[0], ax=axis, label=\"m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5479479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Turn our images into a dataloader with the right transforms\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We might want to train lots of slightly different models, so write big function for the training + monitoring plots\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from torch.autograd import Variable\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _gp_plot(training_metrics, lambda_gp, plot_dir):\n",
    "    fig = training_metrics.plot_gp_wd_ratio(lambda_gp)\n",
    "\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_plot(train_metrics, g_lr, d_lr, plot_dir):\n",
    "    fig = train_metrics.plot_param_gradients(g_lr, d_lr)\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_norm_plot(train_metrics, plot_dir):\n",
    "    fig = train_metrics.plot_critic_grad_norms()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _imgs_plot(imgs, plot_dir, title):\n",
    "    fig = img_validation.show(imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.suptitle(f\"Generated images\")\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _hist_plot(imgs, dataloader, plot_dir, title):\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    img_validation.hist(\n",
    "        next(iter(dataloader)),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(f\"Image Hists - {title}\")\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _fft_plot(imgs, plot_dir, title):\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    img_validation.fft(imgs, axis=axes[0])\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    img_validation.fft(next(iter(dataloader)), axis=axes[1])\n",
    "    axes[1].set_title(f\"Real images FFT {title}\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    hyperparams: dcgan.GANHyperParams,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    img_size: int,\n",
    "    batch_size: int,\n",
    "    output_dir: pathlib.Path,\n",
    ") -> tuple[torch.nn.Module, torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "\n",
    "    Returns G + D and some metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Train the GAN\n",
    "    (generator, discriminator, train_metrics) = dcgan.train_new_gan(\n",
    "        dataloader,\n",
    "        hyperparams,\n",
    "        \"cuda\",\n",
    "        img_size=img_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    title = f\"g_lr={hyperparams.g_lr=}, d_lr={hyperparams.d_lr}\"\n",
    "\n",
    "    # Plot training losses\n",
    "    fig = train_metrics.plot_scores()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_dir/ \"losses.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(train_metrics, hyperparams.lambda_gp, output_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(train_metrics, hyperparams.g_lr, hyperparams.d_lr, output_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(train_metrics, output_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    gen_imgs = dcgan._gen_imgs(generator, batch_size)\n",
    "    _imgs_plot(gen_imgs, output_dir, title)\n",
    "    _hist_plot(gen_imgs, dataloader, output_dir, title)\n",
    "    _fft_plot(gen_imgs, output_dir, title)\n",
    "\n",
    "    # Track metrics\n",
    "    metrics[\"mean_wd_gp_ratio\"] = (\n",
    "        hyperparams.lambda_gp\n",
    "        * np.mean(train_metrics.gradient_penalties, axis=1)\n",
    "        / np.mean(train_metrics.wasserstein_dists, axis=1)\n",
    "    ).mean()\n",
    "    metrics[\"1-mean_gradient_ratio\"] = abs(\n",
    "        1\n",
    "        - (\n",
    "            (hyperparams.g_lr * train_metrics.generator_param_gradients)\n",
    "            / (hyperparams.d_lr * train_metrics.critic_param_gradients)\n",
    "        ).mean()\n",
    "    )\n",
    "    metrics[\"avg_grad_norm\"] = np.mean(train_metrics.critic_interp_grad_norms, axis=1)[\n",
    "        -50:\n",
    "    ].mean()\n",
    "    metrics[\"hist_wasserstein\"] = wasserstein_distance(\n",
    "        gen_imgs.detach().cpu().numpy().flatten(),\n",
    "        next(iter(dataloader)).cpu().numpy().flatten(),\n",
    "    )\n",
    "\n",
    "    return generator, discriminator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "output_dir = pathlib.Path(\"outputs/gan_test/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "hyperparams = dcgan.GANHyperParams(\n",
    "    n_epochs=21,\n",
    "    g_lr=0.005,\n",
    "    d_lr=0.0004,\n",
    "    n_critic=5,\n",
    "    lambda_gp=12,\n",
    "    generator_latent_dim=64,\n",
    "    n_discriminator_blocks=4,\n",
    ")\n",
    "\n",
    "train_gan(\n",
    "    hyperparams,\n",
    "    dataloader,\n",
    "    img_size=tile_size,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326cc56",
   "metadata": {},
   "source": [
    "Tuning\n",
    "----\n",
    "Here, we're looking for:\n",
    " - FID drops early (first 15 epochs)\n",
    " - Gradient norm near 1\n",
    " - $\\lambda$ GP / |W| mostly between 0.1 and 0.6\n",
    " - Wasserstein distance peaks at first, then small positive plateau (without oscillations)\n",
    "\n",
    "We will perform a random search over some of our parameters so that we can find a decent set to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a lot of different GANs with different hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "n_runs = 50\n",
    "n_epochs = 10\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "metrics: list[dict] = []\n",
    "out_dir = pathlib.Path(\"outputs/gan_tuning/\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(n_runs):\n",
    "    hyperparams = dcgan.GANHyperParams(\n",
    "        n_epochs=n_epochs,\n",
    "        lr=10 ** rng.uniform(-6, -2),\n",
    "        d_g_lr_ratio=rng.uniform(2, 32),\n",
    "        n_critic=hyperparams.n_critic,\n",
    "        lambda_gp=np.random.uniform(1, 20),\n",
    "        n_fid_batches=4,\n",
    "        generator_latent_dim=hyperparams.generator_latent_dim,\n",
    "        n_discriminator_blocks=hyperparams.n_discriminator_blocks,\n",
    "    )\n",
    "\n",
    "    output_dir = out_dir / str(i)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    _, _, tmp = train_gan(\n",
    "        hyperparams,\n",
    "        dataloader,\n",
    "        img_size=tile_size,\n",
    "        batch_size=batch_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    tmp[\"lr\"] = hyperparams.lr\n",
    "    tmp[\"lambda_gp\"] = hyperparams.lambda_gp\n",
    "    tmp[\"d_g_lr_ratio\"] = hyperparams.d_g_lr_ratio\n",
    "    metrics.append(tmp)\n",
    "\n",
    "with open(\"metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the metrics\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Lots of plots will have been made with interactive mode off, so close them all\n",
    "# and then turn it back on\n",
    "plt.close(\"all\")\n",
    "plt.ion()\n",
    "\n",
    "with open(\"metrics.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 5))\n",
    "param_names = [\"lr\", \"lambda_gp\", \"d_g_lr_ratio\"]\n",
    "metric_names = [k for k in metrics[0] if k not in param_names]\n",
    "for axis, key in zip(axes.flat, metric_names):\n",
    "    axis.plot([d[key] for d in metrics], \"o\")\n",
    "    axis.set_title(key)\n",
    "    if \"wd_gp\" in key:\n",
    "        axis.axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(-3, 3)\n",
    "    if \"gradient_ratio\" in key:\n",
    "        axis.axhline(0.85, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(0, 2)\n",
    "    if \"grad_norm\" in key:\n",
    "        axis.axhline(0.9, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.1, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(0, 2)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the best runs according to each metric\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "metric_table = pd.DataFrame(metrics)\n",
    "\n",
    "top_n = 5\n",
    "\n",
    "print(\"FID: best, final\")\n",
    "display(metric_table.sort_values(\"best_fid\").head(top_n)[param_names + [\"best_fid\"]])\n",
    "display(metric_table.sort_values(\"final_fid\").head(top_n)[param_names + [\"final_fid\"]])\n",
    "\n",
    "# we want to find how close this one is to 0.3\n",
    "print(\"Gradient penalty strength\")\n",
    "display(\n",
    "    metric_table.assign(wd_gp_diff=lambda df: abs(df[\"mean_wd_gp_ratio\"] - 0.3))\n",
    "    .sort_values(\"wd_gp_diff\")\n",
    "    .head(top_n)[param_names + [\"mean_wd_gp_ratio\"]]\n",
    ")\n",
    "\n",
    "print(\"Gradient ratios\")\n",
    "display(\n",
    "    metric_table.sort_values(\"1-mean_gradient_ratio\").head(top_n)[\n",
    "        param_names + [\"1-mean_gradient_ratio\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Gradient norm\")\n",
    "display(\n",
    "    metric_table.assign(grad_norm_diff=lambda df: abs(df[\"avg_grad_norm\"] - 1.0))\n",
    "    .sort_values(\"grad_norm_diff\")\n",
    "    .head(top_n)[param_names + [\"avg_grad_norm\"]]\n",
    ")\n",
    "\n",
    "print(\"Wasserstein\")\n",
    "display(\n",
    "    metric_table.sort_values(\"hist_wasserstein\").head(top_n)[\n",
    "        param_names + [\"hist_wasserstein\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8831da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the metrics against the hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(len(metric_names), len(param_names), figsize=(12, 12))\n",
    "for ax, key in zip(axes, metric_names):\n",
    "    for axis, param in zip(ax, param_names):\n",
    "        sc = axis.scatter(\n",
    "            [d[param] for d in metrics],\n",
    "            [d[key] for d in metrics],\n",
    "            alpha=0.7,\n",
    "            label=param,\n",
    "            s=1,\n",
    "        )\n",
    "\n",
    "\n",
    "for axis, title in zip(axes[0], param_names):\n",
    "    axis.set_title(title)\n",
    "\n",
    "for axis, title in zip(axes[:, 0], metric_names):\n",
    "    axis.set_ylabel(title)\n",
    "    axis.set_xscale(\"log\")\n",
    "\n",
    "for axis in axes[2]:\n",
    "    axis.set_ylim(0, 1)\n",
    "    axis.axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "for axis in axes[4]:\n",
    "    axis.axhline(0.8, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f15228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now that we have a sensible d_g_lr_ratio, train a longer run\n",
    "\"\"\"\n",
    "\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 128\n",
    "config = {\n",
    "    \"n_epochs\": 300,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": 13.7,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"d_g_lr_ratio\": 12.7,\n",
    "    \"latent_dim\": 64,\n",
    "    \"img_size\": tile_size,\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": pathlib.Path(\"outputs/gan_final/\"),\n",
    "    \"plot_interval\": 10,\n",
    "}\n",
    "\n",
    "generator, discriminator, _ = train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34967dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), config[\"output_dir\"] / \"generator_final.pth\")\n",
    "torch.save(discriminator.state_dict(), config[\"output_dir\"] / \"discriminator_final.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
