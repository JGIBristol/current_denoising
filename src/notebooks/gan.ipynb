{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d26870",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c09b7",
   "metadata": {},
   "source": [
    "GAN Training\n",
    "====\n",
    "An illustration of the GAN training data/loop\n",
    "\n",
    "We'll take some patches of pure-noise (from the deep ocean, with low RMS - we expect these tiles to be pure noise, since the signal is slowly varying)\n",
    "and train a GAN to reproduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Take some tiles from our noisy data and display them, to illustrate what's going on\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from current_denoising.plotting import maps\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "\n",
    "# This is the \"real\" file the Laura made plots of in her paper doi:10.1017/eds.2023.41\n",
    "filepath = pathlib.Path(\n",
    "    \"/home/mh19137/geog_rdsf/data/projects/SING/richard_stuff/Table2/currents/dtu18_eigen-6c4_do0280_rr0004_cs.dat\"\n",
    ")\n",
    "assert filepath.exists()\n",
    "data = ioutils.read_currents(filepath)\n",
    "\n",
    "# Extract some tiles, rejecting the ones with high latitude or RMS\n",
    "# An RMS of 0.20 is the 50th percentile in the dtu18_eigen-6c4_do0280_rr0004_cs data,\n",
    "# and we use the same latitude threshold as Laura did\n",
    "tile_size = 32  # in grid points\n",
    "rms_threshold = 0.18\n",
    "latitude_threshold = 64.0\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    data,\n",
    "    num_tiles=512,\n",
    "    max_rms=rms_threshold,\n",
    "    max_latitude=64.0,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tile_grid = np.ones_like(data) * np.nan\n",
    "\n",
    "for tile, (y, x) in zip(tiles, indices):\n",
    "    tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(10, 5))\n",
    "maps.imshow(tile_grid, axis=axis)\n",
    "axis.imshow(\n",
    "    1.4 * np.isnan(data),\n",
    "    cmap=maps.clear2black_cmap(),\n",
    "    extent=[-180, 180, -90, 90],\n",
    "    vmin=0,\n",
    "    vmax=1.4,\n",
    ")\n",
    "fig.colorbar(axis.images[0], ax=axis, label=\"m/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5479479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Turn our images into a dataloader with the right transforms\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34420d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We might want to train lots of slightly different models, so write big function for the training + monitoring plots\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from torch.autograd import Variable\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _gp_plot(training_metrics, lambda_gp, plot_dir):\n",
    "    fig = training_metrics.plot_gp_wd_ratio(lambda_gp)\n",
    "\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_plot(train_metrics, g_lr, d_lr, plot_dir):\n",
    "    fig = train_metrics.plot_param_gradients(g_lr, d_lr)\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_norm_plot(train_metrics, plot_dir):\n",
    "    fig = train_metrics.plot_critic_grad_norms()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _imgs_plot(imgs, plot_dir, title):\n",
    "    fig = img_validation.show(imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.suptitle(f\"Generated images\")\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _hist_plot(imgs, dataloader, plot_dir, title):\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    img_validation.hist(\n",
    "        next(iter(dataloader)),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(f\"Image Hists - {title}\")\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _fft_plot(imgs, plot_dir, title):\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    _, gen_fft = img_validation.fft(imgs, axis=axes[0])\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    _, real_fft = img_validation.fft(next(iter(dataloader)), axis=axes[1])\n",
    "    axes[1].set_title(f\"Real images FFT {title}\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(real_fft.sum(), gen_fft.sum())\n",
    "    fft_mse = np.mean((gen_fft - real_fft) **2)\n",
    "\n",
    "    return fft_mse\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    hyperparams: dcgan.GANHyperParams,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    img_size: int,\n",
    "    batch_size: int,\n",
    "    output_dir: pathlib.Path,\n",
    ") -> tuple[torch.nn.Module, torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "\n",
    "    Returns G + D and some metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Train the GAN\n",
    "    (generator, discriminator, train_metrics) = dcgan.train_new_gan(\n",
    "        dataloader,\n",
    "        hyperparams,\n",
    "        \"cuda\",\n",
    "        img_size=img_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    title = f\"g_lr={hyperparams.g_lr=}, d_lr={hyperparams.d_lr}\"\n",
    "\n",
    "    # Plot training losses\n",
    "    fig = train_metrics.plot_scores()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_dir / \"losses.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(train_metrics, hyperparams.lambda_gp, output_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(train_metrics, hyperparams.g_lr, hyperparams.d_lr, output_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(train_metrics, output_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    gen_imgs = dcgan._gen_imgs(generator, batch_size)\n",
    "    _imgs_plot(gen_imgs, output_dir, title)\n",
    "    _hist_plot(gen_imgs, dataloader, output_dir, title)\n",
    "    fft_mse = _fft_plot(gen_imgs, output_dir, title)\n",
    "\n",
    "    # Track metrics\n",
    "    metrics[\"mean_wd_gp_ratio\"] = (\n",
    "        hyperparams.lambda_gp\n",
    "        * np.mean(train_metrics.gradient_penalties, axis=1)\n",
    "        / np.mean(train_metrics.wasserstein_dists, axis=1)\n",
    "    ).mean()\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"mean_gradient_ratio\"] = abs(\n",
    "        (\n",
    "            (hyperparams.g_lr * train_metrics.generator_param_gradients[-30:])\n",
    "            / (hyperparams.d_lr * train_metrics.critic_param_gradients[-30:])\n",
    "        ).mean()\n",
    "    )\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"avg_grad_norm\"] = np.mean(train_metrics.critic_interp_grad_norms, axis=1)[\n",
    "        -30:\n",
    "    ].mean()\n",
    "\n",
    "    metrics[\"hist_wasserstein\"] = wasserstein_distance(\n",
    "        gen_imgs.detach().cpu().numpy().flatten(),\n",
    "        next(iter(dataloader)).cpu().numpy().flatten(),\n",
    "    )\n",
    "    metrics[\"fft_mse\"] = fft_mse\n",
    "\n",
    "    return generator, discriminator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "output_dir = pathlib.Path(\"outputs/gan_test/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "# LR of 0.00002 is too low\n",
    "# LR of 0.02 is too high\n",
    "hyperparams = dcgan.GANHyperParams(\n",
    "    n_epochs=5,\n",
    "    g_lr=0.001,\n",
    "    d_lr=0.0002,\n",
    "    n_critic=5,\n",
    "    lambda_gp=12,\n",
    "    generator_latent_dim=64,\n",
    "    n_discriminator_blocks=4,\n",
    ")\n",
    "\n",
    "train_gan(\n",
    "    hyperparams,\n",
    "    dataloader,\n",
    "    img_size=tile_size,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326cc56",
   "metadata": {},
   "source": [
    "Tuning\n",
    "----\n",
    "Here, we're looking for:\n",
    " - Gradient norm near 1\n",
    " - $\\lambda$ GP / |W| mostly between 0.1 and 0.6\n",
    " - Wasserstein distance peaks at first, then small positive plateau (without oscillations)\n",
    "\n",
    "We will perform a random search over some of our parameters so that we can find a decent set to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a lot of different GANs with different hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "n_runs = 500\n",
    "n_epochs = 75\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "metrics: list[dict] = []\n",
    "out_dir = pathlib.Path(\"outputs/gan_tuning/\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(n_runs):\n",
    "    hyperparams = dcgan.GANHyperParams(\n",
    "        n_epochs=n_epochs,\n",
    "        g_lr=10 ** rng.uniform(-5, -2),\n",
    "        d_lr=10 ** rng.uniform(-5, -2),\n",
    "        n_critic=rng.integers(1, 10),\n",
    "        lambda_gp=np.random.uniform(0, 20),\n",
    "        generator_latent_dim=64,\n",
    "        n_discriminator_blocks=4,\n",
    "    )\n",
    "\n",
    "    output_dir = out_dir / str(i)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    _, _, tmp = train_gan(\n",
    "        hyperparams,\n",
    "        dataloader,\n",
    "        img_size=tile_size,\n",
    "        batch_size=batch_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    tmp[\"g_lr\"] = hyperparams.g_lr\n",
    "    tmp[\"d_lr\"] = hyperparams.d_lr\n",
    "    tmp[\"lambda_gp\"] = hyperparams.lambda_gp\n",
    "    tmp[\"n_critic\"] = hyperparams.n_critic\n",
    "    metrics.append(tmp)\n",
    "\n",
    "with open(\"metrics.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the metrics\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Lots of plots will have been made with interactive mode off, so close them all\n",
    "# and then turn it back on\n",
    "plt.close(\"all\")\n",
    "plt.ion()\n",
    "\n",
    "with open(\"metrics.pkl\", \"rb\") as f:\n",
    "    metrics = pickle.load(f)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "param_names = [\"g_lr\", \"d_lr\", \"lambda_gp\", \"n_critic\"]\n",
    "metric_names = [k for k in metrics[0] if k not in param_names]\n",
    "for axis, key in zip(axes.flat, metric_names):\n",
    "    axis.plot([d[key] for d in metrics], \"o\", markersize=1)\n",
    "    axis.set_title(key)\n",
    "    if \"wd_gp\" in key:\n",
    "        axis.axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(-3, 3)\n",
    "    if \"gradient_ratio\" in key:\n",
    "        axis.axhline(0.85, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(0, 2)\n",
    "    if \"grad_norm\" in key:\n",
    "        axis.axhline(0.9, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.1, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.set_ylim(0, 2)\n",
    "    \n",
    "axes[3].set_yscale(\"log\")\n",
    "fig.supxlabel(\"Run number\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8831da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the metrics against the hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(len(metric_names), len(param_names), figsize=(12, 12))\n",
    "for ax, key in zip(axes, metric_names):\n",
    "    for axis, param in zip(ax, param_names):\n",
    "        sc = axis.scatter(\n",
    "            [d[param] for d in metrics],\n",
    "            [d[key] for d in metrics],\n",
    "            alpha=0.7,\n",
    "            label=param,\n",
    "            s=1,\n",
    "        )\n",
    "\n",
    "\n",
    "for axis, title in zip(axes[0], param_names):\n",
    "    axis.set_title(title)\n",
    "\n",
    "for axis, title in zip(axes[:, 0], metric_names):\n",
    "    axis.set_ylabel(title)\n",
    "    axis.set_xscale(\"log\")\n",
    "\n",
    "for axis, title in zip(axes[:, 1], metric_names):\n",
    "    axis.set_xscale(\"log\")\n",
    "\n",
    "for axis in axes[0]:\n",
    "    axis.set_ylim(0, 1)\n",
    "    axis.axhline(0.6, color=\"k\", linestyle=\"dashed\")\n",
    "    axis.axhline(0.1, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "for a in axes[1:3]:\n",
    "    for axis in a:\n",
    "        axis.set_ylim(0, 2)\n",
    "        axis.axhline(0.8, color=\"k\", linestyle=\"dashed\")\n",
    "        axis.axhline(1.2, color=\"k\", linestyle=\"dashed\")\n",
    "\n",
    "for axis in axes[3]:\n",
    "    axis.set_yscale(\"log\")\n",
    "\n",
    "example_params = {\"g_lr\": 1e-3, \"d_lr\": 1e-3, \"lambda_gp\": 5, \"n_critic\": 7}\n",
    "for col, param in zip(axes.T, example_params.values()):\n",
    "    for axis in col:\n",
    "        axis.axvline(param, color=\"r\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Make a new dataframe showing the divergence away from the expected values\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "loss_df = pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "def wd_gp_loss(x):\n",
    "    \"\"\"punish for being below 0.1 or above 0.6\"\"\"\n",
    "    if 0.1 < x < 0.6:\n",
    "        return 0\n",
    "    if x <= 0.1:\n",
    "        return 0.1 - x\n",
    "    return x - 0.6\n",
    "\n",
    "\n",
    "loss_df[\"wd_gp_loss\"] = loss_df[\"mean_wd_gp_ratio\"].apply(wd_gp_loss)\n",
    "\n",
    "loss_df[\"grad_ratio_loss\"] = loss_df[\"mean_gradient_ratio\"].apply(lambda x: abs(x - 1))\n",
    "\n",
    "loss_df[\"grad_norm_loss\"] = loss_df[\"avg_grad_norm\"].apply(lambda x: abs(x - 1))\n",
    "loss_df[\"wasserstein_loss\"] = loss_df[\"hist_wasserstein\"]\n",
    "\n",
    "loss_df = loss_df.drop(columns=metric_names)\n",
    "loss_column_names = loss_df.columns[4:]\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot 1d scatter plots of the losses against run number\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "for axis, key in zip(axes.flat, loss_column_names):\n",
    "    axis.plot(loss_df[key], \"o\", markersize=1)\n",
    "    axis.set_title(key)\n",
    "\n",
    "axes[0].set_ylim(-1, 5)\n",
    "axes[1].set_ylim(-1, 5)\n",
    "axes[2].set_ylim(-1, 3)\n",
    "axes[3].set_yscale(\"log\")\n",
    "fig.supxlabel(\"Run number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9941042",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot a pairplot-esque grid of losses and hyperparams\n",
    "\"\"\"\n",
    "\n",
    "scatter_kw = {\"s\": 5}\n",
    "\n",
    "for loss_name in loss_column_names:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(9, 6))\n",
    "    for ax, m1 in zip(axes, param_names):\n",
    "        for axis, m2 in zip(ax, [p for p in param_names if p != m1]):\n",
    "            im = axis.scatter(\n",
    "                loss_df[m2], loss_df[m1], c=loss_df[loss_name], **scatter_kw\n",
    "            )\n",
    "            axis.set_xlabel(m2)\n",
    "            axis.set_ylabel(m1)\n",
    "\n",
    "            if m1.endswith(\"lr\"):\n",
    "                axis.set_yscale(\"log\")\n",
    "            if m2.endswith(\"lr\"):\n",
    "                axis.set_xscale(\"log\")\n",
    "\n",
    "    fig.suptitle(loss_name)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dc762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot a 2d scatter plot of hist wasserstein distance against the LRs\n",
    "\"\"\"\n",
    "from matplotlib.colors import LogNorm\n",
    "# TODO also do this with some metric for the FFTs\n",
    "\n",
    "fig, axis = plt.subplots()\n",
    "\n",
    "scatter = axis.scatter(\n",
    "    [d[\"g_lr\"] for d in metrics],\n",
    "    [d[\"d_lr\"] for d in metrics],\n",
    "    c=[d[\"hist_wasserstein\"] for d in metrics],\n",
    "    s=10,\n",
    "    norm=LogNorm(),\n",
    "    cmap=\"plasma_r\"\n",
    ")\n",
    "axis.loglog()\n",
    "fig.colorbar(scatter, label=\"Hist Wasserstein Distance\")\n",
    "axis.set_xlabel(\"g_lr\")\n",
    "axis.set_ylabel(\"d_lr\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot a 3D surface of hist wasserstein distance against the LRs\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "g_lrs = loss_df[\"g_lr\"]\n",
    "d_lrs = loss_df[\"d_lr\"]\n",
    "wds = loss_df[\"wasserstein_loss\"]\n",
    "\n",
    "log_g_lrs = np.log10(g_lrs)\n",
    "log_d_lrs = np.log10(d_lrs)\n",
    "\n",
    "surf = ax.plot_trisurf(\n",
    "    log_g_lrs,\n",
    "    log_d_lrs,\n",
    "    wds,\n",
    "    cmap=\"magma\",\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"log10(g_lr)\")\n",
    "ax.set_ylabel(\"log10(d_lr)\")\n",
    "ax.set_zlabel(\"Hist Wasserstein Distance\")\n",
    "fig.colorbar(surf, ax=ax, label=\"Hist Wasserstein Distance\", shrink=0.5)\n",
    "\n",
    "ax.view_init(azim=45)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f15228",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now that we have a sensible d_g_lr_ratio, train a longer run\n",
    "\"\"\"\n",
    "\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 128\n",
    "config = {\n",
    "    \"n_epochs\": 300,\n",
    "    \"n_critic\": 5,\n",
    "    \"lambda_gp\": 13.7,\n",
    "    \"learning_rate\": 0.005,\n",
    "    \"d_g_lr_ratio\": 12.7,\n",
    "    \"latent_dim\": 64,\n",
    "    \"img_size\": tile_size,\n",
    "    \"channels\": 1,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"dataloader\": torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    ),\n",
    "    \"output_dir\": pathlib.Path(\"outputs/gan_final/\"),\n",
    "    \"plot_interval\": 10,\n",
    "}\n",
    "\n",
    "generator, discriminator, _ = train_gan(config, config[\"output_dir\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34967dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), config[\"output_dir\"] / \"generator_final.pth\")\n",
    "torch.save(discriminator.state_dict(), config[\"output_dir\"] / \"discriminator_final.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
