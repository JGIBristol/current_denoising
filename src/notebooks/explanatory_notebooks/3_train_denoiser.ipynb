{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d209423",
   "metadata": {},
   "source": [
    "Train Denoising Model\n",
    "====\n",
    "\n",
    "First we'll look at the data used to train the model, then we'll train it.\n",
    "\n",
    "The model itself is a basic U-Net (with an attention mechanism); we'll train it on pairs of tiles from our clean MDT and noisy MDT residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc22686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Need to mount the SING RDSF dir somewhere\n",
    "rdsf_dir = pathlib.Path(\"~/geog_rdsf/\").expanduser()\n",
    "\n",
    "noisy_filepath = (\n",
    "    rdsf_dir\n",
    "    / \"data\"\n",
    "    / \"projects\"\n",
    "    / \"SING\"\n",
    "    / \"richard_stuff\"\n",
    "    / \"Table2\"\n",
    "    / \"dtu18_eigen-6c4_do0280_rr0004.dat\"\n",
    ")\n",
    "clean_filepath = (\n",
    "    rdsf_dir / \"data\" / \"projects\" / \"dtop\" / \"cmip6\" / \"cmip6_historical_mdts_yr5.dat\"\n",
    ")\n",
    "\n",
    "assert noisy_filepath.exists()\n",
    "assert clean_filepath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59078e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "# It's called read_currents, but actually just reads the array\n",
    "noisy_mdt = ioutils.read_currents(noisy_filepath)\n",
    "noisy_mdt[noisy_mdt == -1.9e19] = np.nan\n",
    "\n",
    "clean_mdt = ioutils.read_clean_mdt(\n",
    "    path=clean_filepath,\n",
    "    metadata_path=clean_filepath.with_stem(clean_filepath.stem + \"_meta\").with_suffix(\n",
    "        \".txt\"\n",
    "    ),\n",
    "    year=2001,\n",
    "    model=\"CMCC-CM2-HR4\",\n",
    "    remove_mean=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ea737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the residuals\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.utils import util\n",
    "\n",
    "sigma_km = 200\n",
    "\n",
    "noisy_residual = util.get_residual(noisy_mdt, sigma_km)\n",
    "clean_residual = util.get_residual(clean_mdt, sigma_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4dd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import CenteredNorm\n",
    "\n",
    "from current_denoising.plotting import maps\n",
    "\n",
    "\n",
    "def mdt_imshow(current_grid: np.ndarray, axis: plt.Axes, norm=None, **kwargs):\n",
    "    \"\"\"Imshow for MDTs - no extent set\"\"\"\n",
    "    lat, long = util.lat_long_grid(current_grid.shape)\n",
    "    extent = kwargs.get(\"extent\", [long[0], long[-1], lat[0], lat[-1]])\n",
    "\n",
    "    imshow_kw = {\n",
    "        \"origin\": \"upper\",\n",
    "        \"cmap\": \"seismic\",\n",
    "    }\n",
    "    imshow_kw.update(kwargs)\n",
    "    imshow_kw[\"extent\"] = extent\n",
    "\n",
    "    im = axis.imshow(current_grid, norm=norm, **imshow_kw)\n",
    "    im.set_extent(extent)\n",
    "\n",
    "    # Plot also the land\n",
    "    axis.imshow(\n",
    "        np.isnan(current_grid),\n",
    "        cmap=maps.clear2black_cmap(),\n",
    "        extent=extent,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        origin=\"upper\",\n",
    "    )\n",
    "\n",
    "    # Add a colorbar\n",
    "    axis.get_figure().colorbar(im, ax=axis)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(18, 18))\n",
    "\n",
    "mdt_imshow(noisy_residual, axes[0], norm=CenteredNorm(vcenter=0.0, halfrange=0.5))\n",
    "mdt_imshow(clean_residual, axes[1], norm=CenteredNorm(vcenter=0.0, halfrange=0.5))\n",
    "\n",
    "axes[0].set_ylabel(\"Noisy\")\n",
    "axes[1].set_ylabel(\"Clean\")\n",
    "\n",
    "fig.suptitle(f\"Residual: smoothed $\\sigma=${sigma_km}km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82cdfe",
   "metadata": {},
   "source": [
    "The signal is readily apparent in the clean (lower) plot. Important regions include the large currents near the East coast of the USA, around Japan, around Australia and around Madagascar.\n",
    "\n",
    "We will not train our denoiser directly on these samples, since this will leave us with no statistically independent testing data.\n",
    "We will instead train a GAN model to generate tiles of noise (see [the other notebook](./2_train_gan.ipynb)), apply these noise tiles\n",
    "to tiles of our clean residual and train the denoiser on this.\n",
    "\n",
    "It may be apparent from the noisy (upper) plot above that the noise strength is not uniform everywhere - it roughly scales with the\n",
    "size of the signal, and some other geographic features like proximity\n",
    "to the coast.\n",
    "To model this, we will apply a noise strength factor to our synthetic noise tiles - in the first instance, this is just the\n",
    "distance from the coast (such that regions nearer the coast have\n",
    "more noise applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2aa7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO - something reasonable here\n",
    "\"\"\"\n",
    "\n",
    "strength_map = np.ones_like(noisy_residual)\n",
    "\n",
    "plt.imshow(strength_map)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.title(\"Noise strength map\")\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c216fb",
   "metadata": {},
   "source": [
    "We will extract tiles from the clean residual and apply GAN generated noise to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d076e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot some e\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "from current_denoising.denoising import data\n",
    "\n",
    "# We need the noise tiles (that were used for GAN training)\n",
    "# so that we can rescale the generated noise to the right\n",
    "# mean/std\n",
    "tile_size = 32\n",
    "latitude_threshhold = 60.0\n",
    "forbidden_mask = ioutils.distance_from_land(noisy_residual) < 20\n",
    "\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    noisy_residual,\n",
    "    forbidden_mask=forbidden_mask,\n",
    "    tile_criterion=ioutils.select_tile,\n",
    "    max_latitude=latitude_threshhold,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")\n",
    "\n",
    "latent_channels = 32\n",
    "latent_size = 4\n",
    "n_gen = 4\n",
    "\n",
    "generator = dcgan.Generator(tile_size, latent_channels, latent_size)\n",
    "generator.load_state_dict(\n",
    "    torch.load(pathlib.Path(\"outputs/mdt_gan/test/\") / \"generator_final.pth\")\n",
    ")\n",
    "_ = generator.to(\"cuda\")\n",
    "\n",
    "# Generate some GAN tiles\n",
    "# By passing a larger latent size to the generator, we get\n",
    "# larger output - this also tells us what size tiles to extract.\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    generator,\n",
    "    n_tiles=n_gen,\n",
    "    noise_size=4 * latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "gen_tiles = tiles.mean() + tiles.std() * (gen_tiles - gen_tiles.mean()) / (\n",
    "    gen_tiles.std() + 1e-8\n",
    ")\n",
    "\n",
    "# Apply noise\n",
    "max_nan_fraction = 0.3\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# We will get warned about not having enough tiles; we don't care\n",
    "# so suppress this\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    tile_pairs, indices = data.get_training_pairs(\n",
    "        clean_residual,\n",
    "        strength_map,\n",
    "        gen_tiles,\n",
    "        max_latitude=latitude_threshhold,\n",
    "        max_nan_fraction=max_nan_fraction,\n",
    "        rng=rng,\n",
    "        return_indices=True,\n",
    "    )\n",
    "\n",
    "# Get the real noisy tiles out at the right positions, to compare\n",
    "real_tiles = util.tiles_from_indices(noisy_residual, indices, gen_tiles.shape[1])\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "kw = {\"origin\": \"upper\", \"cmap\": \"seismic\", \"vmin\": -0.5, \"vmax\": 0.5}\n",
    "for axs, clean, gen_tile, noisy, real in zip(\n",
    "    axes.T, tile_pairs[:, 0], gen_tiles, tile_pairs[:, 1], real_tiles\n",
    "):\n",
    "    axs[0].imshow(clean, **kw)\n",
    "    axs[1].imshow(gen_tile, **kw)\n",
    "    axs[2].imshow(noisy, **kw)\n",
    "    axs[3].imshow(real, **kw)\n",
    "\n",
    "    for axis in axs:\n",
    "        axis.set_xticks([])\n",
    "        axis.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Clean\")\n",
    "axes[1, 0].set_ylabel(\"Synthetic Noise\")\n",
    "axes[2, 0].set_ylabel(\"Synthetic Noisy\")\n",
    "axes[3, 0].set_ylabel(\"Real Noisy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ea4eff",
   "metadata": {},
   "source": [
    "Now that we've seens some examples of the training data and how it's built, we'll make our actual dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1fa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate some training data + perform train/test split\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_gen = 196  # Needs to be > the number of tiles\n",
    "batch_size = 4  # Should probably be small - we drop the last batch each iteration\n",
    "\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    generator,\n",
    "    n_tiles=n_gen,\n",
    "    noise_size=4 * latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "gen_tiles = tiles.mean() + tiles.std() * (gen_tiles - gen_tiles.mean()) / (\n",
    "    gen_tiles.std() + 1e-8\n",
    ")\n",
    "\n",
    "tile_pairs, indices = data.get_training_pairs(\n",
    "    clean_residual,\n",
    "    strength_map,\n",
    "    gen_tiles,\n",
    "    max_latitude=latitude_threshhold,\n",
    "    max_nan_fraction=max_nan_fraction,\n",
    "    rng=rng,\n",
    "    return_indices=True,\n",
    ")\n",
    "clean_tiles, noisy_tiles = np.moveaxis(tile_pairs, 1, 0)\n",
    "\n",
    "# Get the real noisy tiles out at the right positions, to compare\n",
    "real_tiles = util.tiles_from_indices(noisy_residual, indices, gen_tiles.shape[1])\n",
    "\n",
    "(\n",
    "    clean_train,\n",
    "    clean_test,\n",
    "    noisy_train,\n",
    "    noisy_test,\n",
    "    real_train,\n",
    "    real_test,\n",
    "    idx_train,\n",
    "    idx_test,\n",
    ") = train_test_split(clean_tiles, noisy_tiles, real_tiles, indices, train_size=0.8)\n",
    "\n",
    "train_config = data.DataConfig(train=True, batch_size=batch_size, num_workers=4)\n",
    "train_loader = data.dataloader(clean_train, noisy_train, train_config)\n",
    "\n",
    "test_config = data.DataConfig(train=False, batch_size=batch_size, num_workers=0)\n",
    "test_loader = data.dataloader(clean_test, noisy_test, test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed3107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot some tiles - the training data has augmentations applied\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "for ax_row, clean, noisy in zip(axes.T, batch[0], batch[1], strict=True):\n",
    "    ax_row[0].imshow(clean.squeeze(), **kw)\n",
    "    ax_row[0].imshow(torch.isnan(clean).squeeze(), cmap=maps.clear2black_cmap())\n",
    "\n",
    "    ax_row[1].imshow(torch.isnan(noisy).squeeze(), cmap=maps.clear2black_cmap())\n",
    "    ax_row[1].imshow(noisy.squeeze(), **kw)\n",
    "\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "fig.suptitle(\"Training Data\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c00721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot validation data (which doesn't have augmentations applied)\n",
    "\"\"\"\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "for ax_row, clean, noisy in zip(axes.T, batch[0], batch[1], strict=True):\n",
    "    ax_row[0].imshow(clean.squeeze(), **kw)\n",
    "\n",
    "    ax_row[1].imshow(noisy.squeeze(), **kw)\n",
    "\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "fig.suptitle(\"Validation Data\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from current_denoising.denoising import model, train\n",
    "\n",
    "net = model.get_attention_unet(4, 0.1)\n",
    "net, train_loss, val_loss = train.train_model(\n",
    "    net, \"cuda\", n_epochs=250, train_data=train_loader, val_data=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from current_denoising.plotting import training\n",
    "\n",
    "fig = training.plot_losses(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Save the denoiser\n",
    "\"\"\"\n",
    "output_dir = pathlib.Path(\"outputs/mdt_gan/test/\")\n",
    "torch.save(net.state_dict(), output_dir / \"denoiser.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e14abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Denoise on some real noisy tiles\n",
    "\n",
    "These patches were from the testing data - i.e. not in the regions used to train\n",
    "the model\n",
    "\"\"\"\n",
    "from current_denoising.denoising import inference\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "\n",
    "kw = {\"vmin\": -0.5, \"vmax\": 0.5, \"cmap\": \"seismic\"}\n",
    "for axs, noisy, clean in zip(axes.T, real_test, clean_test):\n",
    "    axs[0].imshow(noisy, **kw)\n",
    "    axs[1].imshow(clean, **kw)\n",
    "\n",
    "    denoised = inference.denoise(net, noisy).squeeze()\n",
    "    axs[2].imshow(denoised, **kw)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Noisy (original)\")\n",
    "axes[1, 0].set_ylabel(\"Clean (target)\")\n",
    "axes[2, 0].set_ylabel(\"Denoised\")\n",
    "fig.suptitle(\"Noisy Residual\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
