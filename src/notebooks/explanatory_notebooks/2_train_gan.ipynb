{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afefc36",
   "metadata": {},
   "source": [
    "GAN Training\n",
    "====\n",
    "Train the GAN, make some monitoring plots and store it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94777a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Need to mount the SING RDSF dir somewhere\n",
    "rdsf_dir = pathlib.Path(\"~/geog_rdsf/\").expanduser()\n",
    "\n",
    "noisy_filepath = (\n",
    "    rdsf_dir\n",
    "    / \"data\"\n",
    "    / \"projects\"\n",
    "    / \"SING\"\n",
    "    / \"richard_stuff\"\n",
    "    / \"Table2\"\n",
    "    / \"dtu18_eigen-6c4_do0280_rr0004.dat\"\n",
    ")\n",
    "clean_filepath = (\n",
    "    rdsf_dir / \"data\" / \"projects\" / \"dtop\" / \"cmip6\" / \"cmip6_historical_mdts_yr5.dat\"\n",
    ")\n",
    "\n",
    "assert noisy_filepath.exists()\n",
    "assert clean_filepath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fa804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "# It's called read_currents, but actually just reads the array\n",
    "noisy_mdt = ioutils.read_currents(noisy_filepath)\n",
    "noisy_mdt[noisy_mdt == -1.9e19] = np.nan\n",
    "\n",
    "clean_mdt = ioutils.read_clean_mdt(\n",
    "    path=clean_filepath,\n",
    "    metadata_path=clean_filepath.with_stem(clean_filepath.stem + \"_meta\").with_suffix(\n",
    "        \".txt\"\n",
    "    ),\n",
    "    year=2001,\n",
    "    model=\"CMCC-CM2-HR4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the residual between the MDT and the smoothed MDT\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.utils import util\n",
    "\n",
    "sigma_km = 200\n",
    "residual = util.get_residual(noisy_mdt, sigma_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27601abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select some tiles from the residual based on some criteria\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.plotting import maps\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "tile_size = 32\n",
    "num_tiles = 512\n",
    "latitude_threshhold = 60.0\n",
    "forbidden_mask = ioutils.distance_from_land(residual) < 20\n",
    "\n",
    "# Get the tiles from our map based on the criteria\n",
    "# Return the indices (their locations) for plotting\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    residual,\n",
    "    forbidden_mask=forbidden_mask,\n",
    "    tile_criterion=ioutils.select_tile,\n",
    "    max_latitude=latitude_threshhold,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ecbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a simple GAN on these tiles\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _gp_plot(training_metrics, lambda_gp, plot_dir):\n",
    "    fig = training_metrics.plot_gp_wd_ratio(lambda_gp)\n",
    "\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_plot(train_metrics, g_lr, d_lr, plot_dir):\n",
    "    fig = train_metrics.plot_param_gradients(g_lr, d_lr)\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_norm_plot(train_metrics, plot_dir):\n",
    "    fig = train_metrics.plot_critic_grad_norms()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _imgs_plot(imgs, plot_dir, title):\n",
    "    fig = img_validation.show(imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.suptitle(f\"Generated images\")\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _hist_plot(imgs, dataloader, plot_dir, title):\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    img_validation.hist(\n",
    "        next(iter(dataloader)),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(f\"Image Hists - {title}\")\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _fft_plot(imgs, plot_dir, title):\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    _, gen_fft = img_validation.fft(imgs, axis=axes[0])\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    _, real_fft = img_validation.fft(next(iter(dataloader)), axis=axes[1])\n",
    "    axes[1].set_title(f\"Real images FFT {title}\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fft_mse = np.mean((gen_fft - real_fft) ** 2)\n",
    "\n",
    "    return fft_mse\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    hyperparams: dcgan.GANHyperParams,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    img_size: int,\n",
    "    batch_size: int,\n",
    "    output_dir: pathlib.Path,\n",
    ") -> tuple[torch.nn.Module, torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "\n",
    "    Returns G + D and some metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Train the GAN\n",
    "    (generator, discriminator, train_metrics) = dcgan.train_new_gan(\n",
    "        dataloader,\n",
    "        hyperparams,\n",
    "        \"cuda\",\n",
    "        img_size=img_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    title = f\"g_lr={hyperparams.g_lr=}, d_lr={hyperparams.d_lr}\"\n",
    "\n",
    "    # Plot training losses\n",
    "    fig = train_metrics.plot_scores()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_dir / \"losses.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(train_metrics, hyperparams.lambda_gp, output_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(train_metrics, hyperparams.g_lr, hyperparams.d_lr, output_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(train_metrics, output_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    gen_imgs = generator.gen_imgs(batch_size, hyperparams.generator_latent_size)\n",
    "    _imgs_plot(gen_imgs, output_dir, title)\n",
    "    _hist_plot(gen_imgs, dataloader, output_dir, title)\n",
    "    fft_mse = _fft_plot(gen_imgs, output_dir, title)\n",
    "\n",
    "    # Track metrics\n",
    "    metrics[\"mean_wd_gp_ratio\"] = (\n",
    "        hyperparams.lambda_gp\n",
    "        * np.mean(train_metrics.gradient_penalties, axis=1)\n",
    "        / np.mean(train_metrics.wasserstein_dists, axis=1)\n",
    "    ).mean()\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"mean_gradient_ratio\"] = abs(\n",
    "        (\n",
    "            (hyperparams.g_lr * train_metrics.generator_param_gradients[-30:])\n",
    "            / (hyperparams.d_lr * train_metrics.critic_param_gradients[-30:])\n",
    "        ).mean()\n",
    "    )\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"avg_grad_norm\"] = np.mean(train_metrics.critic_interp_grad_norms, axis=1)[\n",
    "        -30:\n",
    "    ].mean()\n",
    "\n",
    "    metrics[\"hist_wasserstein\"] = wasserstein_distance(\n",
    "        gen_imgs.detach().cpu().numpy().flatten(),\n",
    "        next(iter(dataloader)).cpu().numpy().flatten(),\n",
    "    )\n",
    "    metrics[\"fft_mse\"] = fft_mse\n",
    "\n",
    "    return generator, discriminator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a70909",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "output_dir = pathlib.Path(\"outputs/mdt_gan/test/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hyperparams = dcgan.GANHyperParams(\n",
    "    n_epochs=1000,\n",
    "    g_lr=0.0002,\n",
    "    d_lr=0.0002,\n",
    "    n_critic=5,\n",
    "    lambda_gp=20,\n",
    "    generator_latent_channels=32,\n",
    "    generator_latent_size=4,\n",
    "    n_discriminator_blocks=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "gen, critic, metrics = train_gan(\n",
    "    hyperparams,\n",
    "    dataloader,\n",
    "    img_size=tile_size,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), output_dir / \"generator_final.pth\")\n",
    "torch.save(critic.state_dict(), output_dir / \"discriminator_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecfc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and display some example tiles\n",
    "\"\"\"\n",
    "\n",
    "n_gen = 25\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    gen,\n",
    "    n_tiles=n_gen,\n",
    "    noise_size=hyperparams.generator_latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Give them the right mean and std\n",
    "scaled = tiles.mean() + tiles.std() * (gen_tiles - gen_tiles.mean()) / (\n",
    "    gen_tiles.std() + 1e-8\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "for axis, img in zip(axes.flat, scaled):\n",
    "    im = axis.imshow(img, cmap=\"seismic\", vmin=-0.5, vmax=0.5)\n",
    "    im.set_extent([0, 32, 0, 32])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cax, label=\"Mean Dynamic Topography /m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot histograms of generated and training tiles - \n",
    "\"\"\"\n",
    "fig, axis = plt.subplots()\n",
    "kw = {\"histtype\": \"step\", \"bins\": np.linspace(-0.3, 0.3, 100), \"density\": True}\n",
    "axis.hist(tiles.flat, **kw)\n",
    "axis.hist(scaled.flat, **kw)\n",
    "\n",
    "scaled.std(), tiles.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976378a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and display some example tiles\n",
    "\"\"\"\n",
    "\n",
    "n_gen = 25\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    gen,\n",
    "    n_tiles=n_gen,\n",
    "    noise_size=4*hyperparams.generator_latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Give them the right mean and std\n",
    "scaled = tiles.mean() + tiles.std() * (gen_tiles - gen_tiles.mean()) / (\n",
    "    gen_tiles.std() + 1e-8\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "for axis, img in zip(axes.flat, scaled):\n",
    "    im = axis.imshow(img, cmap=\"seismic\", vmin=-0.5, vmax=0.5)\n",
    "    im.set_extent([0, 32, 0, 32])\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cax, label=\"Mean Dynamic Topography /m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
