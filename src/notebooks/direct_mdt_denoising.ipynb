{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf0bec7",
   "metadata": {},
   "source": [
    "Denoise the MDT directly\n",
    "====\n",
    "Instead of working with currents (gradient of MDT, times some constants + coriolis parameter) we can probably smooth + denoise the MDT directly\n",
    "\n",
    "Read in MDTs\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953de65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Need to mount the SING RDSF dir somewhere\n",
    "rdsf_dir = pathlib.Path(\"~/geog_rdsf/\").expanduser()\n",
    "\n",
    "noisy_filepath = (\n",
    "    rdsf_dir\n",
    "    / \"data\"\n",
    "    / \"projects\"\n",
    "    / \"SING\"\n",
    "    / \"richard_stuff\"\n",
    "    / \"Table2\"\n",
    "    / \"dtu18_eigen-6c4_do0280_rr0004.dat\"\n",
    ")\n",
    "clean_filepath = (\n",
    "    rdsf_dir / \"data\" / \"projects\" / \"dtop\" / \"cmip6\" / \"cmip6_historical_mdts_yr5.dat\"\n",
    ")\n",
    "\n",
    "assert noisy_filepath.exists()\n",
    "assert clean_filepath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe512e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "# It's called read_currents, but actually just reads the array\n",
    "noisy_mdt = ioutils.read_currents(noisy_filepath)\n",
    "noisy_mdt[noisy_mdt == -1.9e19] = np.nan\n",
    "clean_mdt = ioutils.read_clean_mdt(\n",
    "    path=clean_filepath,\n",
    "    metadata_path=clean_filepath.with_stem(clean_filepath.stem + \"_meta\").with_suffix(\n",
    "        \".txt\"\n",
    "    ),\n",
    "    year=2001,\n",
    "    model=\"CMCC-CM2-HR4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66248ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import AxesImage\n",
    "\n",
    "from current_denoising.utils import util\n",
    "\n",
    "\n",
    "def mdt_imshow(current_grid: np.ndarray, axis: plt.Axes, **kwargs) -> AxesImage:\n",
    "    \"\"\"Imshow for MDTs - no extent set\"\"\"\n",
    "    lat, long = util.lat_long_grid(current_grid.shape)\n",
    "    extent = kwargs.get(\"extent\", [long[0], long[-1], lat[0], lat[-1]])\n",
    "\n",
    "    imshow_kw = {\n",
    "        \"origin\": \"upper\",\n",
    "        \"cmap\": \"Spectral\",\n",
    "        \"vmax\": 2,\n",
    "        \"vmin\": -2,\n",
    "    }\n",
    "    imshow_kw.update(kwargs)\n",
    "    imshow_kw[\"extent\"] = extent\n",
    "\n",
    "    im = axis.imshow(current_grid, **imshow_kw)\n",
    "    im.set_extent(extent)\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "im = mdt_imshow(noisy_mdt, axes[0])\n",
    "axes[0].set_title(\"Mean Dynamic Topography (noisy)\")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "im = mdt_imshow(clean_mdt, axes[1])\n",
    "axes[1].set_title(\"MDT (simulated, no noise)\")\n",
    "fig.colorbar(im, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afff4e0",
   "metadata": {},
   "source": [
    "We need to remove NaNs in order to Gaussian smooth\n",
    "----\n",
    "Replace them with their nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22793b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Show the MDT with NaNs replaced by the nearest non-NaN value\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import mdt\n",
    "\n",
    "nan_filled = mdt.fill_nan_with_nearest(noisy_mdt)\n",
    "\n",
    "fig, axis = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "im = mdt_imshow(nan_filled, axis)\n",
    "fig.colorbar(im, ax=axis)\n",
    "axis.set_title(\"NaN replaced by nearest neighbour\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87e8f6",
   "metadata": {},
   "source": [
    "Smooth and find residual\n",
    "----\n",
    "This is the \"noise\" we want to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Applying a Gaussian filter to the gridded field is non-trivial (the grid point size changes with latitude)\n",
    "\"\"\"\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from current_denoising.generation import mdt\n",
    "from current_denoising.utils import util\n",
    "\n",
    "sigma_km = 200\n",
    "sigma_grid = sigma_km / (util.KM_PER_DEG / 4)\n",
    "\n",
    "\n",
    "# TODO for now just do a naive smoothing\n",
    "def naive_smooth(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Invalid but simple smoothing of a gridded field containing NaNs\n",
    "\n",
    "    Invalid since the kernel is constant in size in terms of grid points,\n",
    "    which means it varies in size spatially.\n",
    "    \"\"\"\n",
    "    nan_mask = np.isnan(img)\n",
    "\n",
    "    field = mdt.fill_nan_with_nearest(img)\n",
    "\n",
    "    # 8 grid points -> around 200km radius at equator\n",
    "    field = gaussian_filter(field, sigma=sigma_grid)\n",
    "    return np.where(nan_mask, np.nan, field)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "noisy_mdt_smoothed = naive_smooth(noisy_mdt)\n",
    "residual = noisy_mdt - noisy_mdt_smoothed\n",
    "\n",
    "im = mdt_imshow(noisy_mdt_smoothed, axes[0])\n",
    "axes[0].set_title(\"Gaussian Smoothed MDT (naive)\")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "im = mdt_imshow(residual, axes[1], vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "axes[1].set_title(\"Residual\")\n",
    "fig.colorbar(im, ax=axes[1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "But I've written a function to do it approximately\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def better_smooth(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Approximate smoothing with variable kernel\n",
    "    \"\"\"\n",
    "    nan_mask = np.isnan(img)\n",
    "\n",
    "    field = mdt.fill_nan_with_nearest(img)\n",
    "\n",
    "    # Approximately the same kernel size as above\n",
    "    return np.where(nan_mask, np.nan, mdt.gauss_smooth(field, sigma_km))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "\n",
    "noisy_mdt_smoothed2 = better_smooth(noisy_mdt)\n",
    "residual = noisy_mdt - noisy_mdt_smoothed2\n",
    "\n",
    "smoothing_diff = noisy_mdt_smoothed - noisy_mdt_smoothed2\n",
    "\n",
    "im = mdt_imshow(noisy_mdt_smoothed2, axes[0])\n",
    "axes[0].set_title(\"Smoothed MDT (varying kernel)\")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "im = mdt_imshow(residual, axes[1], vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "axes[1].set_title(\"Residual\")\n",
    "fig.colorbar(im, ax=axes[1])\n",
    "\n",
    "im = mdt_imshow(smoothing_diff, axes[2], vmin=-0.1, vmax=0.1, cmap=\"PiYG\")\n",
    "axes[2].set_title(\"Difference between naive & latitude-dependent smoothing\")\n",
    "fig.colorbar(im, ax=axes[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43341bf2",
   "metadata": {},
   "source": [
    "Optional: train a GAN to generate realistic-looking tiles of MDT noise\n",
    "----\n",
    "\n",
    "So that we have a large set of training data for the denoising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First we use some heuristics to extract some tiles from the MDT residual - we don't want ones that are too far from the equator (they are distorted),\n",
    "and we don't want ones that contain too much variance\n",
    "\"\"\"\n",
    "\n",
    "from math import isqrt\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "\n",
    "def plot_mdt_tiles(\n",
    "    tiles: np.ndarray, indices: list[tuple[int, int]], grid_shape: tuple[int, int]\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot a grid of tiles (as an Nxshapexshape np array), labelling the lat/longs according\n",
    "    to the indices extracted given that the global gridded field was shaped grid_shape\n",
    "    \"\"\"\n",
    "    n_row = isqrt(tiles.shape[0])\n",
    "    assert (\n",
    "        n_row**2 == tiles.shape[0]\n",
    "    ), f\"must have square number of tiles, got {tiles.shape[0]}\"\n",
    "\n",
    "    fig, axes = plt.subplots(n_row, n_row, figsize=(12, 12))\n",
    "\n",
    "    lat, long = util.lat_long_grid(grid_shape)\n",
    "\n",
    "    for axis, tile, (y, x) in zip(axes.flat, tiles, indices):\n",
    "        im = axis.imshow(tile, origin=\"upper\", vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "        im.set_extent([long[x], long[x + tile_size], lat[y], lat[y + tile_size]])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cax, label=\"Mean Dynamic Topography /m\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "tile_size = 32\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    residual,\n",
    "    num_tiles=25,\n",
    "    max_latitude=np.inf,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")\n",
    "print(indices[0])\n",
    "\n",
    "fig = plot_mdt_tiles(tiles, indices, residual.shape)\n",
    "fig.suptitle(\"Example MDT patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73664e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Choose some tiles as examples, from specific chosen locations on the grid\n",
    "\"\"\"\n",
    "\n",
    "from scipy.stats import moment\n",
    "\n",
    "# Four normal, two distorted by globe, two full of signal near coasts\n",
    "lats = [0, -20, -20, 30, -50, 80, 10, 45]\n",
    "longs = [0, 50, -100, 130, -100, 0, -51, 120]\n",
    "example_tiles = [\n",
    "    util.get_tile(residual, (lat, long), tile_size // 4)\n",
    "    for lat, long in zip(lats, longs)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(8, 3, figsize=(9, 24))\n",
    "\n",
    "bins = np.linspace(-0.3, 0.3, 100)\n",
    "for tile, axs, lat, long in zip(example_tiles, axes, lats, longs):\n",
    "    # Plot the tile\n",
    "    axs[0].imshow(\n",
    "        tile,\n",
    "        extent=[long, long + tile_size // 4, lat, lat + tile_size // 4],\n",
    "        vmin=-0.5,\n",
    "        vmax=0.5,\n",
    "        cmap=\"seismic\",\n",
    "    )\n",
    "\n",
    "    # Plot the hist of this tile\n",
    "    axs[1].hist(tile.flat, bins=bins)\n",
    "    labels = [_, _, \"std\", \"skew\", \"kurtosis\"]\n",
    "    axs[1].set_title(\n",
    "        \" \".join(\n",
    "            [f\"{labels[i]} {moment(tile.flat, order=i, nan_policy='omit'):.4f}\\n\" for i in range(2, 5)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    log_power = np.log2(abs(np.fft.fftshift(np.fft.fft2(tile)))**2)\n",
    "    axs[2].imshow(log_power)\n",
    "\n",
    "axes[0, 0].set_title(\"Tile\")\n",
    "axes[0, 2].set_title(\"log power spectrum\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the amount of Fourier power above a threshold\n",
    "\"\"\"\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "\n",
    "def fft_power_fraction_factory(\n",
    "    window_size: int,\n",
    "    threshold: float,\n",
    "    *,\n",
    "    band: str = \"high\",  # \"high\" for high-freq fraction, \"low\" for low-freq fraction\n",
    ") -> Callable[..., np.ndarray]:\n",
    "    \"\"\"\n",
    "    Build a callable(arr, axis=(-2,-1)) -> ndarray that returns the fraction of FFT power\n",
    "    in a radial band relative to total power over the given axes.\n",
    "\n",
    "    threshold is in [0,1] relative to Nyquist radius.\n",
    "    band = \"high\" -> r_norm >= threshold\n",
    "    band = \"low\"  -> r_norm <= threshold\n",
    "    \"\"\"\n",
    "    y, x = np.indices((window_size, window_size))\n",
    "    cy, cx = window_size // 2, window_size // 2\n",
    "    r = np.hypot(x - cx, y - cy)\n",
    "    r_norm = r / r.max()\n",
    "\n",
    "    if band == \"high\":\n",
    "        mask = r_norm >= threshold\n",
    "    elif band == \"low\":\n",
    "        mask = r_norm <= threshold\n",
    "    else:\n",
    "        raise ValueError(f\"band must be 'high' or 'low', got {band!r}\")\n",
    "\n",
    "    mask = mask.astype(float)  # for multiplication\n",
    "\n",
    "    def _f(arr: np.ndarray, axis: tuple[int, int] = (-2, -1)) -> np.ndarray:\n",
    "        # Fill NaNs per-window with the window nanmean\n",
    "        means = np.nanmean(arr, axis=axis, keepdims=True)\n",
    "        arr_filled = np.where(np.isnan(arr), means, arr)\n",
    "\n",
    "        # FFT over the window axes\n",
    "        f = np.fft.fft2(arr_filled, axes=axis)\n",
    "        f = np.fft.fftshift(f, axes=axis)\n",
    "        power = np.abs(f) ** 2\n",
    "\n",
    "        # Sum band power vs total power over the same axes\n",
    "        # mask broadcasts over the last two dims (the window axes)\n",
    "        band_power = (power * mask).sum(axis=axis)\n",
    "        total_power = power.sum(axis=axis)\n",
    "\n",
    "        return band_power / total_power\n",
    "\n",
    "    return _f\n",
    "\n",
    "\n",
    "def apply_to_map(f):\n",
    "    retval = util.apply_to_sliding_window(residual, f, tile_size)\n",
    "    return np.where(np.isnan(residual), np.nan, retval)\n",
    "\n",
    "\n",
    "power_threshold = 0.05  # The power threshold\n",
    "fft_power_fcn = fft_power_fraction_factory(tile_size, power_threshold, band=\"high\")\n",
    "power_fraction_map = apply_to_map(fft_power_fcn)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "im = mdt_imshow(\n",
    "    power_fraction_map,\n",
    "    axes[0],\n",
    "    cmap=\"RdGy_r\",\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    ")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "axes[0].set_title(f\"Tile FFT power > {100*power_threshold}% of max\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe0433",
   "metadata": {},
   "source": [
    "Choose tiles to keep based on our criteria\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the selected tiles on a map with the latitudes indicated. Hopefully we can see that we've de-selected ones near the coasts\n",
    "\n",
    "This will e.g. select for tiles that have 80% of their power in frequencies above 5% of the minimum\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.plotting import maps\n",
    "\n",
    "latitude_threshhold = 64.0\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    residual,\n",
    "    num_tiles=1024,\n",
    "    tile_criterion=(lambda x: -ioutils.fft_fraction(x, power_threshold), -power_fraction),\n",
    "    max_latitude=latitude_threshhold,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")\n",
    "\n",
    "tile_grid = np.ones_like(residual) * np.nan\n",
    "\n",
    "for tile, (y, x) in zip(tiles, indices):\n",
    "    tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(16, 9))\n",
    "im = mdt_imshow(tile_grid, axis=axis, vmin=-0.3, vmax=0.3, cmap=\"seismic\")\n",
    "fig.colorbar(im, ax=axis)\n",
    "\n",
    "lat, long = util.lat_long_grid(tile_grid.shape)\n",
    "extent = [long[0], long[-1], lat[0], lat[-1]]\n",
    "\n",
    "axis.imshow(\n",
    "    np.isnan(residual),\n",
    "    cmap=maps.clear2black_cmap(),\n",
    "    extent=extent,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    origin=\"upper\",\n",
    ")\n",
    "\n",
    "for t in (latitude_threshhold, -latitude_threshhold):\n",
    "    axis.axhline(t, color=\"r\", linestyle=\"--\")\n",
    "axis.text(-197, latitude_threshhold, f\"{latitude_threshhold}\" + r\"$\\degree$\", color=\"r\")\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Extracted patches; keeping tiles with\\n{power_fraction*100}% of power above {power_threshold*100}% of the maximum\"\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5316cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_mdt_tiles(tiles[:25], indices[:25], residual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"to stop the GAN executing if i dont want it to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a simple GAN on these tiles\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _gp_plot(training_metrics, lambda_gp, plot_dir):\n",
    "    fig = training_metrics.plot_gp_wd_ratio(lambda_gp)\n",
    "\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_plot(train_metrics, g_lr, d_lr, plot_dir):\n",
    "    fig = train_metrics.plot_param_gradients(g_lr, d_lr)\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_norm_plot(train_metrics, plot_dir):\n",
    "    fig = train_metrics.plot_critic_grad_norms()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _imgs_plot(imgs, plot_dir, title):\n",
    "    fig = img_validation.show(imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.suptitle(f\"Generated images\")\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _hist_plot(imgs, dataloader, plot_dir, title):\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    img_validation.hist(\n",
    "        next(iter(dataloader)),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(f\"Image Hists - {title}\")\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _fft_plot(imgs, plot_dir, title):\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    _, gen_fft = img_validation.fft(imgs, axis=axes[0])\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    _, real_fft = img_validation.fft(next(iter(dataloader)), axis=axes[1])\n",
    "    axes[1].set_title(f\"Real images FFT {title}\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fft_mse = np.mean((gen_fft - real_fft) ** 2)\n",
    "\n",
    "    return fft_mse\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    hyperparams: dcgan.GANHyperParams,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    img_size: int,\n",
    "    batch_size: int,\n",
    "    output_dir: pathlib.Path,\n",
    ") -> tuple[torch.nn.Module, torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "\n",
    "    Returns G + D and some metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Train the GAN\n",
    "    (generator, discriminator, train_metrics) = dcgan.train_new_gan(\n",
    "        dataloader,\n",
    "        hyperparams,\n",
    "        \"cuda\",\n",
    "        img_size=img_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    title = f\"g_lr={hyperparams.g_lr=}, d_lr={hyperparams.d_lr}\"\n",
    "\n",
    "    # Plot training losses\n",
    "    fig = train_metrics.plot_scores()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_dir / \"losses.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(train_metrics, hyperparams.lambda_gp, output_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(train_metrics, hyperparams.g_lr, hyperparams.d_lr, output_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(train_metrics, output_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    gen_imgs = generator.gen_imgs(batch_size, hyperparams.generator_latent_size)\n",
    "    _imgs_plot(gen_imgs, output_dir, title)\n",
    "    _hist_plot(gen_imgs, dataloader, output_dir, title)\n",
    "    fft_mse = _fft_plot(gen_imgs, output_dir, title)\n",
    "\n",
    "    # Track metrics\n",
    "    metrics[\"mean_wd_gp_ratio\"] = (\n",
    "        hyperparams.lambda_gp\n",
    "        * np.mean(train_metrics.gradient_penalties, axis=1)\n",
    "        / np.mean(train_metrics.wasserstein_dists, axis=1)\n",
    "    ).mean()\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"mean_gradient_ratio\"] = abs(\n",
    "        (\n",
    "            (hyperparams.g_lr * train_metrics.generator_param_gradients[-30:])\n",
    "            / (hyperparams.d_lr * train_metrics.critic_param_gradients[-30:])\n",
    "        ).mean()\n",
    "    )\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"avg_grad_norm\"] = np.mean(train_metrics.critic_interp_grad_norms, axis=1)[\n",
    "        -30:\n",
    "    ].mean()\n",
    "\n",
    "    metrics[\"hist_wasserstein\"] = wasserstein_distance(\n",
    "        gen_imgs.detach().cpu().numpy().flatten(),\n",
    "        next(iter(dataloader)).cpu().numpy().flatten(),\n",
    "    )\n",
    "    metrics[\"fft_mse\"] = fft_mse\n",
    "\n",
    "    return generator, discriminator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "output_dir = pathlib.Path(\"outputs/mdt_gan/test/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "hyperparams = dcgan.GANHyperParams(\n",
    "    n_epochs=500,\n",
    "    g_lr=0.0002,\n",
    "    d_lr=0.0002,\n",
    "    n_critic=5,\n",
    "    lambda_gp=20,\n",
    "    generator_latent_channels=32,\n",
    "    generator_latent_size=4,\n",
    "    n_discriminator_blocks=4,\n",
    ")\n",
    "\n",
    "gen, critic, metrics = train_gan(\n",
    "    hyperparams,\n",
    "    dataloader,\n",
    "    img_size=tile_size,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca8898",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), output_dir / \"generator_final.pth\")\n",
    "torch.save(critic.state_dict(), output_dir / \"discriminator_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and display some example tiles\n",
    "\"\"\"\n",
    "\n",
    "n_gen = 16\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    gen, n_tiles=n_gen, noise_size=hyperparams.generator_latent_size, device=\"cuda\"\n",
    ")\n",
    "scaled = (gen_tiles - gen_tiles.mean()) / (gen_tiles.max() - gen_tiles.min())\n",
    "plot_mdt_tiles(scaled, np.zeros((n_gen, 2), dtype=int), (100, 100)).suptitle(\n",
    "    f\"Output size: {scaled[0].shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Repeat with a larger input size, to demonstrate the outfilling\n",
    "\"\"\"\n",
    "\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    gen, n_tiles=n_gen, noise_size=2 * hyperparams.generator_latent_size, device=\"cuda\"\n",
    ")\n",
    "scaled = (gen_tiles - gen_tiles.mean()) / (gen_tiles.max() - gen_tiles.min())\n",
    "fig = plot_mdt_tiles(scaled, np.zeros((n_gen, 2), dtype=int), (100, 100))\n",
    "\n",
    "fig.suptitle(f\"Output size: {scaled[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de196f76",
   "metadata": {},
   "source": [
    "Stitch these tiles together\n",
    "----\n",
    "As a comparison, stitch the tiles together using quilting - this will likely give us something less good than the native GAN outfilling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac566c5",
   "metadata": {},
   "source": [
    "Train the denoising model\n",
    "----\n",
    "Train the denoising model with synthetic noise + real patches of clean MDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909ec2a",
   "metadata": {},
   "source": [
    "Evaluate the denoising model on different noisy MDTs\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
