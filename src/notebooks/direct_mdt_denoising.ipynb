{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf0bec7",
   "metadata": {},
   "source": [
    "Denoise the MDT directly\n",
    "====\n",
    "Instead of working with currents (gradient of MDT, times some constants + coriolis parameter) we can probably smooth + denoise the MDT directly\n",
    "\n",
    "Read in MDTs\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953de65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Need to mount the SING RDSF dir somewhere\n",
    "rdsf_dir = pathlib.Path(\"~/geog_rdsf/\").expanduser()\n",
    "\n",
    "noisy_filepath = (\n",
    "    rdsf_dir\n",
    "    / \"data\"\n",
    "    / \"projects\"\n",
    "    / \"SING\"\n",
    "    / \"richard_stuff\"\n",
    "    / \"Table2\"\n",
    "    / \"dtu18_eigen-6c4_do0280_rr0004.dat\"\n",
    ")\n",
    "clean_filepath = (\n",
    "    rdsf_dir / \"data\" / \"projects\" / \"dtop\" / \"cmip6\" / \"cmip6_historical_mdts_yr5.dat\"\n",
    ")\n",
    "\n",
    "assert noisy_filepath.exists()\n",
    "assert clean_filepath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe512e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "# It's called read_currents, but actually just reads the array\n",
    "noisy_mdt = ioutils.read_currents(noisy_filepath)\n",
    "noisy_mdt[noisy_mdt == -1.9e19] = np.nan\n",
    "clean_mdt = ioutils.read_clean_mdt(\n",
    "    clean_filepath,\n",
    "    clean_filepath.with_stem(clean_filepath.stem + \"_meta\").with_suffix(\".txt\"),\n",
    "    year=2001,\n",
    "    model=\"CMCC-CM2-HR4\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66248ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import AxesImage\n",
    "\n",
    "from current_denoising.utils import util\n",
    "\n",
    "\n",
    "def mdt_imshow(current_grid: np.ndarray, axis: plt.Axes, **kwargs) -> AxesImage:\n",
    "    \"\"\"Imshow for MDTs - no extent set\"\"\"\n",
    "    lat, long = util.lat_long_grid(current_grid.shape)\n",
    "    extent = kwargs.get(\"extent\", [long[0], long[-1], lat[0], lat[-1]])\n",
    "\n",
    "    imshow_kw = {\n",
    "        \"origin\": \"upper\",\n",
    "        \"cmap\": \"magma\",\n",
    "        \"vmax\": 2,\n",
    "        \"vmin\": -2,\n",
    "    }\n",
    "    imshow_kw.update(kwargs)\n",
    "    imshow_kw[\"extent\"] = extent\n",
    "\n",
    "    im = axis.imshow(current_grid, **imshow_kw)\n",
    "    im.set_extent(extent)\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "im = mdt_imshow(noisy_mdt, axes[0])\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "im = mdt_imshow(clean_mdt, axes[1])\n",
    "fig.colorbar(im, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87e8f6",
   "metadata": {},
   "source": [
    "Smooth and find residual\n",
    "----\n",
    "This is the \"noise\" we want to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Applying a Gaussian filter to the gridded field is non-trivial (the grid point size changes with latitude)\n",
    "\"\"\"\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from current_denoising.generation import mdt\n",
    "from current_denoising.utils import util\n",
    "\n",
    "sigma_km = 200\n",
    "sigma_grid = sigma_km / (util.KM_PER_DEG / 4)\n",
    "\n",
    "# TODO for now just do a naive smoothing\n",
    "def naive_smooth(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Invalid but simple smoothing of a gridded field containing NaNs\n",
    "\n",
    "    Invalid since the kernel is constant in size in terms of grid points,\n",
    "    which means it varies in size spatially.\n",
    "    \"\"\"\n",
    "    nan_mask = np.isnan(img)\n",
    "\n",
    "    field = mdt.fill_nan_with_nearest(img)\n",
    "\n",
    "    # 8 grid points -> around 200km radius at equator\n",
    "    field = gaussian_filter(field, sigma=sigma_grid)\n",
    "    return np.where(nan_mask, np.nan, field)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "\n",
    "noisy_mdt_smoothed = naive_smooth(noisy_mdt)\n",
    "residual = noisy_mdt - noisy_mdt_smoothed\n",
    "\n",
    "im = mdt_imshow(noisy_mdt_smoothed, axes[0])\n",
    "axes[0].set_title(\"Smoothed MDT (naive)\")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "im = mdt_imshow(residual, axes[1], vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "axes[1].set_title(\"Residual\")\n",
    "fig.colorbar(im, ax=axes[1])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bbc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "But I've written a function to do it approximately\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def better_smooth(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Approximate smoothing with variable kernel\n",
    "    \"\"\"\n",
    "    nan_mask = np.isnan(img)\n",
    "\n",
    "    field = mdt.fill_nan_with_nearest(img)\n",
    "\n",
    "    # Approximately the same kernel size as above\n",
    "    return np.where(nan_mask, np.nan, mdt.gauss_smooth(field, sigma_km))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 12))\n",
    "\n",
    "noisy_mdt_smoothed2 = better_smooth(noisy_mdt)\n",
    "residual = noisy_mdt - noisy_mdt_smoothed2\n",
    "\n",
    "smoothing_diff = noisy_mdt_smoothed - noisy_mdt_smoothed2\n",
    "\n",
    "im = mdt_imshow(noisy_mdt_smoothed2, axes[0])\n",
    "axes[0].set_title(\"Smoothed MDT (varying kernel)\")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "\n",
    "im = mdt_imshow(residual, axes[1], vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "axes[1].set_title(\"Residual\")\n",
    "fig.colorbar(im, ax=axes[1])\n",
    "\n",
    "im = mdt_imshow(smoothing_diff, axes[2], vmin=-0.1, vmax=0.1, cmap=\"PiYG\")\n",
    "axes[2].set_title(\"Difference between naive & latitude-dependent smoothing\")\n",
    "fig.colorbar(im, ax=axes[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43341bf2",
   "metadata": {},
   "source": [
    "Optional: train a GAN to generate realistic-looking tiles of MDT noise\n",
    "----\n",
    "\n",
    "So that we have a large set of training data for the denoising model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c3655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First we use some heuristics to extract some tiles from the MDT residual - we don't want ones that are too far from the equator (they are distorted),\n",
    "and we don't want ones that contain too much variance\n",
    "\"\"\"\n",
    "\n",
    "from math import isqrt\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "\n",
    "def plot_mdt_tiles(\n",
    "    tiles: np.ndarray, indices: list[tuple[int, int]], grid_shape: tuple[int, int]\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Plot a grid of tiles (as an Nxshapexshape np array), labelling the lat/longs according\n",
    "    to the indices extracted given that the global gridded field was shaped grid_shape\n",
    "    \"\"\"\n",
    "    n_row = isqrt(tiles.shape[0])\n",
    "    assert (\n",
    "        n_row**2 == tiles.shape[0]\n",
    "    ), f\"must have square number of tiles, got {tiles.shape[0]}\"\n",
    "\n",
    "    fig, axes = plt.subplots(n_row, n_row, figsize=(12, 12))\n",
    "\n",
    "    lat, long = util.lat_long_grid(grid_shape)\n",
    "\n",
    "    for axis, tile, (y, x) in zip(axes.flat, tiles, indices):\n",
    "        im = axis.imshow(tile, origin=\"upper\", vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "        im.set_extent([long[x], long[x + tile_size], lat[y], lat[y + tile_size]])\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cax, label=\"Mean Dynamic Topography /m\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "tile_size = 32\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    residual,\n",
    "    num_tiles=25,\n",
    "    max_rms=np.inf,\n",
    "    max_latitude=np.inf,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")\n",
    "print(indices[0])\n",
    "\n",
    "fig = plot_mdt_tiles(tiles, indices, residual.shape)\n",
    "fig.suptitle(\"Example MDT patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get RMS of tiles and plot a histogram and map of the RMS\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def grid_rms(array: np.ndarray, tile_size: int):\n",
    "    \"\"\"\n",
    "    Get the RMS of a sliding window over our array\n",
    "    \"\"\"\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(array, (tile_size, tile_size))\n",
    "    retval = np.sqrt(np.nanmean(windows**2, axis=(-2, -1)))\n",
    "\n",
    "    pad_width = tile_size - 1\n",
    "    return np.pad(\n",
    "        retval,\n",
    "        ((0, pad_width), (0, pad_width)),\n",
    "        mode=\"constant\",\n",
    "        constant_values=np.nan,\n",
    "    )\n",
    "\n",
    "\n",
    "residual_rms = grid_rms(residual, tile_size)\n",
    "residual_rms[np.isnan(residual)] = np.nan\n",
    "\n",
    "fig, axes = plt.subplots(2, 1)\n",
    "\n",
    "vmin = 0\n",
    "rms_threshhold = 0.25\n",
    "im = mdt_imshow(residual_rms, axes[0], vmin=vmin, vmax=rms_threshhold, cmap=\"viridis\")\n",
    "fig.colorbar(im, ax=axes[0])\n",
    "axes[0].set_title(\"Tile RMS\")\n",
    "\n",
    "axes[1].hist(residual_rms.flat, bins=50, color=\"k\")\n",
    "axes[1].axvline(rms_threshhold, color=\"r\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "\n",
    "n_total = np.sum(~np.isnan(residual_rms))\n",
    "n_below_threshold = np.sum(residual_rms[~np.isnan(residual_rms)] < rms_threshhold)\n",
    "axes[1].set_title(f\"{100*n_below_threshold/n_total:.1f}% of tiles below threshold\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the selected tiles on a map with the latitudes indicated. Hopefully we can see that we've de-selected ones near the coasts\n",
    "from current_denoising.plotting import maps\n",
    "\n",
    "latitude_threshhold = 64.0\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    rng,\n",
    "    residual,\n",
    "    num_tiles=1024,\n",
    "    max_rms=rms_threshhold,\n",
    "    max_latitude=latitude_threshhold,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")\n",
    "\n",
    "tile_grid = np.ones_like(residual) * np.nan\n",
    "\n",
    "for tile, (y, x) in zip(tiles, indices):\n",
    "    tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(16, 9))\n",
    "im = mdt_imshow(tile_grid, axis=axis, vmin=-0.3, vmax=0.3, cmap=\"seismic\")\n",
    "fig.colorbar(im, ax=axis)\n",
    "\n",
    "lat, long = util.lat_long_grid(tile_grid.shape)\n",
    "extent = [long[0], long[-1], lat[0], lat[-1]]\n",
    "\n",
    "axis.imshow(\n",
    "    rms_threshhold * np.isnan(residual),\n",
    "    cmap=maps.clear2black_cmap(),\n",
    "    extent=extent,\n",
    "    vmin=0,\n",
    "    vmax=rms_threshhold,\n",
    "    origin=\"upper\",\n",
    ")\n",
    "\n",
    "for t in (latitude_threshhold, -latitude_threshhold):\n",
    "    axis.axhline(t, color=\"r\", linestyle=\"--\")\n",
    "axis.text(-197, latitude_threshhold, f\"{latitude_threshhold}\" + r\"$\\degree$\", color=\"r\")\n",
    "\n",
    "fig.suptitle(f\"Extracted patches; patch RMS {rms_threshhold=:.2f}m\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5316cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_mdt_tiles(tiles[:25], indices[:25], residual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"to stop the GAN executing if i dont want it to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5714c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train a simple GAN on these tiles\n",
    "\"\"\"\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "dataset = dcgan.TileLoader(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055b0b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "from current_denoising.plotting import training, img_validation\n",
    "\n",
    "\n",
    "def _gp_plot(training_metrics, lambda_gp, plot_dir):\n",
    "    fig = training_metrics.plot_gp_wd_ratio(lambda_gp)\n",
    "\n",
    "    fig.savefig(plot_dir / \"gp_wd.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_plot(train_metrics, g_lr, d_lr, plot_dir):\n",
    "    fig = train_metrics.plot_param_gradients(g_lr, d_lr)\n",
    "    fig.savefig(plot_dir / \"grads.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _grad_norm_plot(train_metrics, plot_dir):\n",
    "    fig = train_metrics.plot_critic_grad_norms()\n",
    "    fig.savefig(plot_dir / \"grad_norm.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _imgs_plot(imgs, plot_dir, title):\n",
    "    fig = img_validation.show(imgs, cmap=\"turbo\")\n",
    "    mappable = cm.ScalarMappable(\n",
    "        norm=colors.Normalize(vmin=0.0, vmax=1.4), cmap=\"turbo\"\n",
    "    )\n",
    "    mappable.set_array([])\n",
    "    fig.colorbar(mappable, ax=fig.axes)\n",
    "    fig.suptitle(f\"Generated images\")\n",
    "    fig.savefig(plot_dir / \"generated.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _hist_plot(imgs, dataloader, plot_dir, title):\n",
    "    fig, axis = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    hist_kw = {\n",
    "        \"bins\": np.linspace(-1, 1, 150),\n",
    "        \"density\": True,\n",
    "        \"alpha\": 0.5,\n",
    "        \"histtype\": \"step\",\n",
    "        \"linewidth\": 2,\n",
    "    }\n",
    "    img_validation.hist(imgs, axis=axis, **hist_kw, label=\"Generated images\")\n",
    "    img_validation.hist(\n",
    "        next(iter(dataloader)),\n",
    "        axis=axis,\n",
    "        **hist_kw,\n",
    "        label=\"Real images\",\n",
    "        linestyle=\"dashed\",\n",
    "    )\n",
    "    axis.set_title(f\"Image Hists - {title}\")\n",
    "    axis.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"hists.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _fft_plot(imgs, plot_dir, title):\n",
    "    # Plot FFTs of the generated and real images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    _, gen_fft = img_validation.fft(imgs, axis=axes[0])\n",
    "    axes[0].set_title(\"Generated images FFT\")\n",
    "\n",
    "    _, real_fft = img_validation.fft(next(iter(dataloader)), axis=axes[1])\n",
    "    axes[1].set_title(f\"Real images FFT {title}\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_dir / \"ffts.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fft_mse = np.mean((gen_fft - real_fft) ** 2)\n",
    "\n",
    "    return fft_mse\n",
    "\n",
    "\n",
    "def train_gan(\n",
    "    hyperparams: dcgan.GANHyperParams,\n",
    "    dataloader: torch.utils.data.DataLoader,\n",
    "    img_size: int,\n",
    "    batch_size: int,\n",
    "    output_dir: pathlib.Path,\n",
    ") -> tuple[torch.nn.Module, torch.nn.Module]:\n",
    "    \"\"\"\n",
    "    Train the GAN and make lots of debug plots\n",
    "\n",
    "    Returns G + D and some metrics\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Train the GAN\n",
    "    (generator, discriminator, train_metrics) = dcgan.train_new_gan(\n",
    "        dataloader,\n",
    "        hyperparams,\n",
    "        \"cuda\",\n",
    "        img_size=img_size,\n",
    "        output_dir=output_dir,\n",
    "    )\n",
    "\n",
    "    title = f\"g_lr={hyperparams.g_lr=}, d_lr={hyperparams.d_lr}\"\n",
    "\n",
    "    # Plot training losses\n",
    "    fig = train_metrics.plot_scores()\n",
    "    fig.suptitle(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(output_dir / \"losses.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Plot contributions of gradient penalty and Wasserstein distance to discriminator loss\n",
    "    _gp_plot(train_metrics, hyperparams.lambda_gp, output_dir)\n",
    "\n",
    "    # Plot gradients\n",
    "    _grad_plot(train_metrics, hyperparams.g_lr, hyperparams.d_lr, output_dir)\n",
    "\n",
    "    # Plot grad norm\n",
    "    _grad_norm_plot(train_metrics, output_dir)\n",
    "\n",
    "    # Generate some images and display them\n",
    "    gen_imgs = dcgan._gen_imgs(generator, batch_size, 1)\n",
    "    _imgs_plot(gen_imgs, output_dir, title)\n",
    "    _hist_plot(gen_imgs, dataloader, output_dir, title)\n",
    "    fft_mse = _fft_plot(gen_imgs, output_dir, title)\n",
    "\n",
    "    # Track metrics\n",
    "    metrics[\"mean_wd_gp_ratio\"] = (\n",
    "        hyperparams.lambda_gp\n",
    "        * np.mean(train_metrics.gradient_penalties, axis=1)\n",
    "        / np.mean(train_metrics.wasserstein_dists, axis=1)\n",
    "    ).mean()\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"mean_gradient_ratio\"] = abs(\n",
    "        (\n",
    "            (hyperparams.g_lr * train_metrics.generator_param_gradients[-30:])\n",
    "            / (hyperparams.d_lr * train_metrics.critic_param_gradients[-30:])\n",
    "        ).mean()\n",
    "    )\n",
    "\n",
    "    # Don't want the first epochs - need to give the model some time to stabilise\n",
    "    metrics[\"avg_grad_norm\"] = np.mean(train_metrics.critic_interp_grad_norms, axis=1)[\n",
    "        -30:\n",
    "    ].mean()\n",
    "\n",
    "    metrics[\"hist_wasserstein\"] = wasserstein_distance(\n",
    "        gen_imgs.detach().cpu().numpy().flatten(),\n",
    "        next(iter(dataloader)).cpu().numpy().flatten(),\n",
    "    )\n",
    "    metrics[\"fft_mse\"] = fft_mse\n",
    "\n",
    "    return generator, discriminator, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ecdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "output_dir = pathlib.Path(\"outputs/mdt_gan/test/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "hyperparams = dcgan.GANHyperParams(\n",
    "    n_epochs=500,\n",
    "    g_lr=0.0007,\n",
    "    d_lr=0.0002,\n",
    "    n_critic=5,\n",
    "    lambda_gp=20,\n",
    "    generator_latent_dim=64,\n",
    "    n_discriminator_blocks=4,\n",
    ")\n",
    "\n",
    "gen, critic, metrics = train_gan(\n",
    "    hyperparams,\n",
    "    dataloader,\n",
    "    img_size=tile_size,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and display some example tiles\n",
    "\"\"\"\n",
    "n_gen = 16\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    gen, n_tiles=n_gen, noise_size=1, device=\"cuda\"\n",
    ")\n",
    "scaled = (gen_tiles - gen_tiles.mean()) / (gen_tiles.max() - gen_tiles.min())\n",
    "plot_mdt_tiles(scaled, np.zeros((n_gen, 2), dtype=int), (100, 100)).suptitle(f\"Output size: {scaled[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Repeat with a larger input size, to demonstrate the outfilling\n",
    "\"\"\"\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    gen, n_tiles=n_gen, noise_size=32, device=\"cuda\"\n",
    ")\n",
    "scaled = (gen_tiles - gen_tiles.mean()) / (gen_tiles.max() - gen_tiles.min())\n",
    "fig = plot_mdt_tiles(scaled, np.zeros((n_gen, 2), dtype=int), (100, 100))\n",
    "\n",
    "fig.suptitle(f\"Output size: {scaled[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de196f76",
   "metadata": {},
   "source": [
    "Optional: stitch these tiles together\n",
    "----\n",
    "We want to train our denoising model on larger patches of MDT, so that it can learn the slowly-varying signal\n",
    "\n",
    "This won't be necessary if our GAN is a TileGAN which can generate arbitrary-sized patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac566c5",
   "metadata": {},
   "source": [
    "Train the denoising model\n",
    "----\n",
    "Train the denoising model with synthetic noise + real patches of clean MDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909ec2a",
   "metadata": {},
   "source": [
    "Evaluate the denoising model on different noisy MDTs\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
