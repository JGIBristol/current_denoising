{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf0bec7",
   "metadata": {},
   "source": [
    "Denoise the MDT directly\n",
    "====\n",
    "Instead of working with currents (gradient of MDT, times some constants + coriolis parameter) we can probably smooth + denoise the MDT directly\n",
    "\n",
    "Read in MDTs\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Need to mount the SING RDSF dir somewhere\n",
    "rdsf_dir = pathlib.Path(\"~/geog_rdsf/\").expanduser()\n",
    "\n",
    "noisy_filepath = (\n",
    "    rdsf_dir\n",
    "    / \"data\"\n",
    "    / \"projects\"\n",
    "    / \"SING\"\n",
    "    / \"richard_stuff\"\n",
    "    / \"Table2\"\n",
    "    / \"dtu18_eigen-6c4_do0280_rr0004.dat\"\n",
    ")\n",
    "clean_filepath = (\n",
    "    rdsf_dir / \"data\" / \"projects\" / \"dtop\" / \"cmip6\" / \"cmip6_historical_mdts_yr5.dat\"\n",
    ")\n",
    "\n",
    "assert noisy_filepath.exists()\n",
    "assert clean_filepath.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe512e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from current_denoising.generation import ioutils\n",
    "\n",
    "# It's called read_currents, but actually just reads the array\n",
    "noisy_mdt = ioutils.read_currents(noisy_filepath)\n",
    "noisy_mdt[noisy_mdt == -1.9e19] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66248ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the residual between the MDT and the smoothed MDT\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.utils import util\n",
    "from current_denoising.generation import mdt\n",
    "\n",
    "sigma_km = 200\n",
    "\n",
    "\n",
    "def get_residual(img: np.ndarray, sigma_km: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the residual (difference) between the provided MDT gridded field and a Gaussian smoothed version.\n",
    "\n",
    "    :param img: the (2d) gridded field from which a residual is extracted.\n",
    "                Land values should be marked with NaN.\n",
    "    :param sigma_km: the size, in km, of the gaussian smoothing filter.\n",
    "\n",
    "    :returns: the (2d) residual between `img` and the smoothed `img`.\n",
    "\n",
    "    Notes:\n",
    "    Performs an approximate smoothing - the size of the smoothing kernel varies with latitude, which is\n",
    "    much more accurate than assuming the grid points are equal sized, but it is still not exact.\n",
    "\n",
    "    The original image may contain NaNs, which will be replaced by their nearest neighbour\n",
    "    values (keeping them as NaN would cause the NaNs to propagate throughout the entire\n",
    "    grid; replacing them with a constant (e.g. 0.0 or the global mean) would distort the residual\n",
    "    near the coasts, which is what we care about). This nearest-neighbour search is not a true\n",
    "    physical nearest neighbour, since it doesn't account for the variation of grid point sizes\n",
    "    with latitude. However, since the nearest neighbour search is performed over very short\n",
    "    distances, it should be good enough.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # Find the difference between the original image and a smoothed version, where we replace\n",
    "    # NaN with their nearest values\n",
    "    nan_mask = np.isnan(img)\n",
    "    smoothed = mdt.gauss_smooth(mdt.fill_nan_with_nearest(img), sigma_km)\n",
    "\n",
    "    # Put NaN values back in to indicate land, and remove the global mean\n",
    "    smoothed = np.where(nan_mask, np.nan, smoothed)\n",
    "\n",
    "    residual = img - smoothed\n",
    "\n",
    "    return ioutils._remove_nanmean(residual)\n",
    "\n",
    "\n",
    "residual = get_residual(noisy_mdt, sigma_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c837e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import CenteredNorm\n",
    "\n",
    "from current_denoising.plotting import maps\n",
    "\n",
    "\n",
    "def mdt_imshow(current_grid: np.ndarray, axis: plt.Axes, norm=None, **kwargs):\n",
    "    \"\"\"Imshow for MDTs - no extent set\"\"\"\n",
    "    lat, long = util.lat_long_grid(current_grid.shape)\n",
    "    extent = kwargs.get(\"extent\", [long[0], long[-1], lat[0], lat[-1]])\n",
    "\n",
    "    imshow_kw = {\n",
    "        \"origin\": \"upper\",\n",
    "        \"cmap\": \"seismic\",\n",
    "    }\n",
    "    imshow_kw.update(kwargs)\n",
    "    imshow_kw[\"extent\"] = extent\n",
    "\n",
    "    im = axis.imshow(current_grid, norm=norm, **imshow_kw)\n",
    "    im.set_extent(extent)\n",
    "\n",
    "    # Plot also the land\n",
    "    axis.imshow(\n",
    "        np.isnan(current_grid),\n",
    "        cmap=maps.clear2black_cmap(),\n",
    "        extent=extent,\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        origin=\"upper\",\n",
    "    )\n",
    "\n",
    "    # Add a colorbar\n",
    "    axis.get_figure().colorbar(im, ax=axis)\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(figsize=(18, 9))\n",
    "\n",
    "mdt_imshow(residual, axis, norm=CenteredNorm(vcenter=0.0, halfrange=0.5))\n",
    "\n",
    "fig.suptitle(f\"Residual: smoothed $\\sigma=${sigma_km}km\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe0433",
   "metadata": {},
   "source": [
    "Choose tiles to use in GAN training\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the selected tiles on a map, according to a selection function\n",
    "\n",
    "This will e.g. select for tiles that have 80% of their power in frequencies above 5% of the minimum\n",
    "\"\"\"\n",
    "\n",
    "tile_size = 32\n",
    "latitude_threshhold = 60.0\n",
    "forbidden_mask = ioutils.distance_from_land(residual) < 20\n",
    "\n",
    "# Get the tiles from our map based on the criteria\n",
    "# Return the indices (their locations) for plotting\n",
    "tiles, indices = ioutils.extract_tiles(\n",
    "    residual,\n",
    "    forbidden_mask=forbidden_mask,\n",
    "    tile_criterion=ioutils.select_tile,\n",
    "    max_latitude=latitude_threshhold,\n",
    "    tile_size=tile_size,\n",
    "    return_indices=True,\n",
    ")\n",
    "\n",
    "num_tiles = len(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c880ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize=(16, 9))\n",
    "\n",
    "\n",
    "def _plot_tiles(tiles, indices, tile_size, axis, **imshow_kw):\n",
    "    \"\"\"\n",
    "    Plot some tiles on an axis, placing them at the provided index\n",
    "    \"\"\"\n",
    "    # Put the tiles into a single numpy array for plotting\n",
    "    tile_grid = np.zeros_like(residual)\n",
    "    for tile, (y, x) in zip(tiles, indices):\n",
    "        tile_grid[y : y + tile_size, x : x + tile_size] = tile\n",
    "\n",
    "    # Put NaNs back in for plotting\n",
    "    tile_grid = np.where(np.isnan(residual), np.nan, tile_grid)\n",
    "\n",
    "    mdt_imshow(tile_grid, axis=axis, norm=CenteredNorm(vcenter=0.0, halfrange=0.5))\n",
    "\n",
    "\n",
    "_plot_tiles(tiles, indices, tile_size, axis, cmap=\"seismic\")\n",
    "\n",
    "\n",
    "for t in (latitude_threshhold, -latitude_threshhold):\n",
    "    axis.axhline(t, color=\"r\", linestyle=\"--\")\n",
    "axis.text(-197, latitude_threshhold, f\"{latitude_threshhold}\" + r\"$\\degree$\", color=\"r\")\n",
    "\n",
    "fig.suptitle(f\"{num_tiles} non-overlapping tiles\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5316cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Show some of the training dataset\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(8, 8))\n",
    "\n",
    "for axis, tile in zip(axes.flat, tiles):\n",
    "    axis.imshow(tile, cmap=\"seismic\", vmin=-0.5, vmax=0.5)\n",
    "    axis.set_xticks([])\n",
    "    axis.set_yticks([])\n",
    "\n",
    "fig.suptitle(\"Training Tiles\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3389115e",
   "metadata": {},
   "source": [
    "Generate some tiles using the GAN\n",
    "----\n",
    "Load the model from memory - it should already be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de35724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from current_denoising.generation import dcgan\n",
    "\n",
    "# We'll read the generator from here\n",
    "output_dir = pathlib.Path(\"explanatory_notebooks/outputs/mdt_gan/test/\")\n",
    "\n",
    "# TODO nicer way of recording the hyperparams in the generator object for later...?\n",
    "# These must match the values with which the generator was trained\n",
    "latent_channels = 32\n",
    "latent_size = 4\n",
    "\n",
    "generator = dcgan.Generator(tile_size, latent_channels, latent_size)\n",
    "generator.load_state_dict(torch.load(output_dir / \"generator_final.pth\"))\n",
    "_ = generator.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465dfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate some tiles\n",
    "\"\"\"\n",
    "\n",
    "n_gen = 25\n",
    "\n",
    "gen_tiles = dcgan.generate_tiles(\n",
    "    generator,\n",
    "    n_tiles=n_gen,\n",
    "    noise_size=latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "scaled = tiles.mean() + tiles.std() * (gen_tiles - gen_tiles.mean()) / (\n",
    "    gen_tiles.std() + 1e-8\n",
    ")\n",
    "fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "\n",
    "for axis, img in zip(axes.flat, scaled):\n",
    "    im = axis.imshow(img, vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "    im.set_extent([0, scaled.shape[1], 0, scaled.shape[2]])\n",
    "\n",
    "fig.suptitle(f\"Output size: {scaled[0].shape}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cax, label=\"Mean Dynamic Topography /m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate some tiles, larger than the training set, by passing the generator a slightly larger random latent vector\n",
    "\"\"\"\n",
    "\n",
    "big_gen_tiles = dcgan.generate_tiles(\n",
    "    generator,\n",
    "    n_tiles=n_gen,\n",
    "    noise_size=4 * latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "big_scaled = tiles.mean() + tiles.std() * (big_gen_tiles - big_gen_tiles.mean()) / (\n",
    "    big_gen_tiles.std() + 1e-8\n",
    ")\n",
    "fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "\n",
    "for axis, img in zip(axes.flat, big_scaled):\n",
    "    im = axis.imshow(img, vmin=-0.5, vmax=0.5, cmap=\"seismic\")\n",
    "    im.set_extent([0, big_scaled.shape[1], 0, big_scaled.shape[2]])\n",
    "\n",
    "fig.suptitle(f\"Output size: {big_scaled[0].shape}\")\n",
    "fig.tight_layout()\n",
    "\n",
    "cax = fig.add_axes([1.05, 0.15, 0.05, 0.7])\n",
    "fig.colorbar(im, cax=cax, label=\"Mean Dynamic Topography /m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de196f76",
   "metadata": {},
   "source": [
    "Stitch these tiles together\n",
    "----\n",
    "As a comparison, stitch the tiles together using quilting - this will likely give us something less good than the native GAN outfilling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb76b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compare real 128x128 patches to quilted ones to ones generated with our GAN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import quilting\n",
    "\n",
    "real_tiles = ioutils.extract_tiles(\n",
    "    residual,\n",
    "    forbidden_mask=None,\n",
    "    # Choose tiles with not much NaN in them, that also pass our RMS and FFT criteria\n",
    "    tile_criterion=lambda tile: ioutils.select_tile(tile)\n",
    "    and (np.sum(np.isnan(tile)) / len(tile.flat) < 0.2),\n",
    "    max_latitude=latitude_threshhold,\n",
    "    tile_size=128,\n",
    "    allow_nan=True,\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(4, 3, figsize=(9, 12))\n",
    "\n",
    "for axs, gen_tile, real_tile in zip(axes, big_scaled, real_tiles):\n",
    "    patches = dcgan.generate_tiles(\n",
    "        generator,\n",
    "        n_tiles=n_gen,\n",
    "        noise_size=latent_size,\n",
    "        device=\"cuda\",\n",
    "    )\n",
    "    patches = tiles.mean() + tiles.std() * (patches - patches.mean()) / (\n",
    "        patches.std() + 1e-8\n",
    "    )\n",
    "\n",
    "    torch.seed()\n",
    "    quilt = quilting.quilt(\n",
    "        patches, target_size=(128, 128), patch_overlap=4, repeat_penalty=0\n",
    "    )\n",
    "\n",
    "    kw = {\"cmap\": \"seismic\", \"vmin\": -0.5, \"vmax\": 0.5}\n",
    "    axs[0].imshow(quilt, **kw)\n",
    "    axs[1].imshow(real_tile, **kw)\n",
    "    axs[2].imshow(gen_tile, **kw)\n",
    "\n",
    "axes[0, 0].set_title(\"Quilted\")\n",
    "axes[0, 1].set_title(\"Real Noise\")\n",
    "axes[0, 2].set_title(\"Native GAN Outfilling\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cef682",
   "metadata": {},
   "source": [
    "Apply this noise to the clean data\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a900f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mdt = ioutils.read_clean_mdt(\n",
    "    path=clean_filepath,\n",
    "    metadata_path=clean_filepath.with_stem(clean_filepath.stem + \"_meta\").with_suffix(\n",
    "        \".txt\"\n",
    "    ),\n",
    "    year=2001,\n",
    "    model=\"CMCC-CM2-HR4\",\n",
    "    remove_mean=True,\n",
    ")\n",
    "\n",
    "clean_residual = get_residual(clean_mdt, sigma_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05579b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(12, 12))\n",
    "mdt_imshow(clean_mdt, axes[0], cmap=\"RdYlGn\", vmin=-1.5, vmax=1.5)\n",
    "\n",
    "axes[0].set_title(\"Clean MDT\")\n",
    "\n",
    "mdt_imshow(clean_residual, axes[1], cmap=\"seismic\", vmin=-0.5, vmax=0.5)\n",
    "\n",
    "axes[1].set_title(\"Clean Residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb81a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our noise should have a location-depdendent strength\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.generation import applying_noise\n",
    "\n",
    "# TODO This just does a naive, latitude-unaware Gaussian smooth of the MDT gradient\n",
    "# Is this the right thing for our strength map? I doubt it\n",
    "# No we want to do an RMS/land-based one - it's very rough so it doesn't matter how accurate we are\n",
    "grad = np.gradient(residual)\n",
    "grad = np.sqrt(grad[0] ** 2 + grad[1] ** 2)\n",
    "strength_map = applying_noise.noise_strength_map(grad, filter_size=10)\n",
    "\n",
    "strength_map = np.ones_like(strength_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3745a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "im = axis.imshow(strength_map)\n",
    "fig.colorbar(im, ax=axis)\n",
    "\n",
    "fig.suptitle(\"Noise strength map\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a0356",
   "metadata": {},
   "source": [
    "We will randomly extract patches of clean signal and apply our noise to them - these pairs will make our denoising training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c9e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract tiles from the clean residual and apply GAN-generated noise to them\n",
    "to build up our training dataset\n",
    "\n",
    "Also extract the corresponding \"true\" noisy and clean tiles for later comparison\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.denoising import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "denoising_patch_size = 128\n",
    "max_nan_fraction = 0.3\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# Generate some noise tiles\n",
    "n_noise_tiles = 32\n",
    "noise_tiles = dcgan.generate_tiles(\n",
    "    generator,\n",
    "    n_tiles=n_noise_tiles,\n",
    "    noise_size=4 * latent_size,\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# Rescale the noise tiles to have the same mean and std as the real noise\n",
    "noise_tiles = noise_tiles - noise_tiles.mean()\n",
    "noise_tiles = tiles.std() * noise_tiles / noise_tiles.std()\n",
    "\n",
    "assert all(\n",
    "    x == denoising_patch_size for x in noise_tiles.shape[1:]\n",
    "), f\"{noise_tiles.shape=}, {denoising_patch_size=}\"\n",
    "\n",
    "# Extract all the training pairs, and return indices\n",
    "tile_pairs, indices = data.get_training_pairs(\n",
    "    clean_residual,\n",
    "    strength_map,\n",
    "    noise_tiles,\n",
    "    max_latitude=latitude_threshhold,\n",
    "    max_nan_fraction=max_nan_fraction,\n",
    "    rng=rng,\n",
    "    return_indices=True,\n",
    ")\n",
    "\n",
    "clean_tiles, noisy_tiles = np.moveaxis(tile_pairs, 1, 0)\n",
    "\n",
    "# Use these indices to get the corresponding real noisy tiles out\n",
    "real_tiles = util.tiles_from_indices(residual, indices, denoising_patch_size)\n",
    "\n",
    "(\n",
    "    clean_train,\n",
    "    clean_test,\n",
    "    noisy_train,\n",
    "    noisy_test,\n",
    "    real_train,\n",
    "    real_test,\n",
    "    idx_train,\n",
    "    idx_test,\n",
    ") = train_test_split(clean_tiles, noisy_tiles, real_tiles, indices, train_size=0.8)\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "\n",
    "# Put the tiles into a single numpy array for plotting\n",
    "_plot_tiles(clean_train, idx_train, denoising_patch_size, axes[0, 0])\n",
    "_plot_tiles(noisy_train, idx_train, denoising_patch_size, axes[1, 0])\n",
    "_plot_tiles(real_train, idx_train, denoising_patch_size, axes[2, 0])\n",
    "\n",
    "_plot_tiles(clean_test, idx_test, denoising_patch_size, axes[0, 1])\n",
    "_plot_tiles(noisy_test, idx_test, denoising_patch_size, axes[1, 1])\n",
    "_plot_tiles(real_test, idx_test, denoising_patch_size, axes[2, 1])\n",
    "\n",
    "axes[0, 0].set_title(\"Training Data\")\n",
    "axes[0, 1].set_title(\"Test Data\")\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Clean\")\n",
    "axes[1, 0].set_ylabel(\"Synthetic\")\n",
    "axes[2, 0].set_ylabel(\"Noisy (real)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac566c5",
   "metadata": {},
   "source": [
    "Train the denoising model\n",
    "----\n",
    "Train the denoising model with synthetic noise + real patches of clean MDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is what the training and testing data looks like\n",
    "\"\"\"\n",
    "batch_size=4\n",
    "train_config = data.DataConfig(train=True, batch_size=batch_size, num_workers=4)\n",
    "train_loader = data.dataloader(clean_train, noisy_train, train_config)\n",
    "\n",
    "test_config = data.DataConfig(train=False, batch_size=batch_size, num_workers=0)\n",
    "test_loader = data.dataloader(clean_test, noisy_test, test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a78f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot some tiles\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "for ax_row, clean, noisy in zip(axes.T, batch[0], batch[1], strict=True):\n",
    "    ax_row[0].imshow(clean.squeeze(), **kw)\n",
    "    ax_row[0].imshow(torch.isnan(clean).squeeze(), cmap=maps.clear2black_cmap())\n",
    "\n",
    "    ax_row[1].imshow(torch.isnan(noisy).squeeze(), cmap=maps.clear2black_cmap())\n",
    "    ax_row[1].imshow(noisy.squeeze(), **kw)\n",
    "\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "fig.suptitle(\"Training Data\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "\n",
    "batch = next(iter(test_loader))\n",
    "for ax_row, clean, noisy in zip(axes.T, batch[0], batch[1], strict=True):\n",
    "    ax_row[0].imshow(clean.squeeze(), **kw)\n",
    "\n",
    "    ax_row[1].imshow(noisy.squeeze(), **kw)\n",
    "\n",
    "    for ax in ax_row:\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "fig.suptitle(\"Validation Data\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d1000",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the denoiser\n",
    "\"\"\"\n",
    "\n",
    "from current_denoising.denoising import model, train\n",
    "\n",
    "net = model.get_attention_unet(4, 0.1)\n",
    "net, train_loss, val_loss = train.train_model(\n",
    "    net, \"cuda\", n_epochs=250, train_data=train_loader, val_data=test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dafff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from current_denoising.plotting import training\n",
    "\n",
    "fig = training.plot_losses(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909ec2a",
   "metadata": {},
   "source": [
    "Evaluate the denoising model on different noisy MDTs\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214f0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "First show it on some test data\n",
    "\"\"\"\n",
    "\n",
    "n_test = 4\n",
    "test_noise = dcgan.generate_tiles(\n",
    "    generator, n_tiles=n_test, noise_size=4 * latent_size, device=\"cuda\"\n",
    ")\n",
    "test_noise = test_noise - test_noise.mean()\n",
    "test_noise = tiles.std() * test_noise / test_noise.std()\n",
    "\n",
    "test_data = data.get_training_pairs(\n",
    "    clean_residual, strength_map, test_noise, max_latitude=latitude_threshhold, rng=rng, max_nan_fraction=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb5526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from current_denoising.denoising import inference\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "\n",
    "for axs, (noisy, clean) in zip(axes.T, test_data):\n",
    "    axs[0].imshow(clean, **kw)\n",
    "    axs[1].imshow(noisy, **kw)\n",
    "\n",
    "    axs[2].imshow(inference.denoise(net, noisy), **kw)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Noisy (original)\")\n",
    "axes[1, 0].set_ylabel(\"Clean (target)\")\n",
    "axes[2, 0].set_ylabel(\"Denoised\")\n",
    "fig.suptitle(\"Validation Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0573a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Denoise on some real noisy tiles\n",
    "\n",
    "These patches were from the testing data - i.e. not in the regions used to train\n",
    "the model\n",
    "\"\"\"\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "\n",
    "kw = {\"vmin\": -0.5, \"vmax\": 0.5, \"cmap\": \"seismic\"}\n",
    "for axs, noisy, clean in zip(axes.T, real_test, clean_test):\n",
    "    axs[0].imshow(noisy, **kw)\n",
    "    axs[1].imshow(clean, **kw)\n",
    "\n",
    "    denoised = inference.denoise(net, noisy).squeeze()\n",
    "    axs[2].imshow(denoised, **kw)\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "axes[0, 0].set_ylabel(\"Noisy (original)\")\n",
    "axes[1, 0].set_ylabel(\"Clean (target)\")\n",
    "axes[2, 0].set_ylabel(\"Denoised\")\n",
    "fig.suptitle(\"Noisy Residual\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "current-denoising (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
